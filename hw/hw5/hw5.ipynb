{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 5: Evaluation metrics\n",
    "### Associated lectures: [Lectures 9, 10](https://ubc-cs.github.io/cpsc330/README.html) \n",
    "\n",
    "**Due date: Monday, Feb 27, 2023 at 11:59pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:3}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2022W2/blob/main/docs/homework_instructions.md). \n",
    "\n",
    "**You may work with a partner on this homework and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 2. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Precision, recall, and f1 score by hand <a name=\"1\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem of predicting whether a patient has cancer or not. It is important to catch this disease early to reduce mortality rate; late diagnosis will result in metastasis to other organs, which adversely impacts patient's prognosis. Below are confusion matrices of two machine learning models: Model A and Model B. \n",
    "\n",
    "- Model A\n",
    "\n",
    "|         | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 48 | 32 |\n",
    "| **Actual no disease**       | 20 | 100 |\n",
    "\n",
    "\n",
    "- Model B\n",
    "\n",
    "|        | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 43 | 22 |\n",
    "| **Actual no disease**       | 35 | 100 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Positive vs. negative class \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Precision, recall, and f1 score depend upon which class is considered \"positive\", that is the thing you wish to find. In the example above, which class is likely to be the \"positive\" class? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class that is likely to serve as the \"positive\" class could be the disease class. The \"positive\" class can be thought of as the class we wish the model to detect. In cases of predicting health conditions, the disease present class is often chosen as the \"positive\" class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Accuracy\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Calculate accuracies for Model A and Model B. \n",
    "\n",
    "We'll store all metrics associated with Model A and Model B in the `results_dict` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\"A\": {}, \"B\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"accuracy\"] = (100 + 48) / (100 + 48 + 32 + 20)\n",
    "results_dict[\"B\"][\"accuracy\"] = (100 + 43) / (100 + 43 + 22 + 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Which model would you pick? \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Which model would you pick simply based on the accuracy metric? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n",
      "0.715\n"
     ]
    }
   ],
   "source": [
    "print(results_dict[\"A\"][\"accuracy\"])\n",
    "print(results_dict[\"B\"][\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solely based on the accuracy scores above, model A has a higher calculated accuracy for our predictions and thus would be considered the better model. This does not take into account that since a late diagnosis is more costly to our situation, we would likely select the model which predicts accurately while minimizing the amount of false positives (predicting no disease when there really is disease). In this case, we would select Model B as it has a smaller rate of false positives than model A. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Precision, recall, f1-score\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Calculate precision, recall, f1-score for Model A and Model B manually, without using `scikit-learn` tools. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"precision\"] = (48)/(48+20)\n",
    "results_dict[\"B\"][\"precision\"] = (43)/(43+35)\n",
    "results_dict[\"A\"][\"recall\"] = (48)/(48+32)\n",
    "results_dict[\"B\"][\"recall\"] = (43)/(43+22)\n",
    "results_dict[\"A\"][\"f1\"] = (2)*((results_dict[\"A\"][\"precision\"] * results_dict[\"A\"][\"recall\"])/(results_dict[\"A\"][\"precision\"] + results_dict[\"A\"][\"recall\"]))\n",
    "results_dict[\"B\"][\"f1\"] = (2)*((results_dict[\"B\"][\"precision\"] * results_dict[\"B\"][\"recall\"])/(results_dict[\"B\"][\"precision\"] + results_dict[\"B\"][\"recall\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the dataframe with all results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.661538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.601399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A         B\n",
       "accuracy   0.740000  0.715000\n",
       "precision  0.705882  0.551282\n",
       "recall     0.600000  0.661538\n",
       "f1         0.648649  0.601399"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Discussion\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Given the type of problem (early cancer diagnosis), which metric is more informative in this problem? Why? \n",
    "2. Which model would you pick based on this information? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Given that we want to reduce late cancer diagnosis, we should reduce the rate of false negative errors. This would mean that recall is more informative as is it directly depends on the rate of false negatives, with higher recall indicating a reduced rate of false negatives and vice versa. \n",
    "\n",
    "2. Model B in this case would be considered the better model as it has a higher recall score than model A, indicating that model B produces less false negative errors than model A, allowing us to optimize for early cancer diagnosis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 1.6 \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Provide 2 to 3 example classification datasets (with links) where accuracy metric would be misleading. Discuss which evaluation metric would be more appropriate for each dataset. You may consider datasets we have used in this course so far. You could also look up datasets on Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Credit card fraud detection dataset. Accuracy metric misleading due to extremely imbalanced classes. Minimizing recall would be the better strategy to ensure as many positive cases as positive are caught. https://www.kaggle.com/mlg-ulb/creditcardfraud.\n",
    "\n",
    "2. Breast Cancer detection dataset. Moderate class imbalance makes accuracy metric misleading. Minimizing precision to reduce false positive errors and consequently unecessary invasive treatment would be the better strategy. https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic).\n",
    "\n",
    "3. Adult Census Income Dataset. Although minimal class imbalance, the real life cost of predicting false positive or false negative errors is not equal. In this case, optimizing either precision or recall would be a better strategy. https://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Classification evaluation metrics using `sklearn` <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "In general, when a dataset is imbalanced, accuracy does not provide the whole story. In class, we looked at credit card fraud dataset which is a classic example of an imbalanced dataset. \n",
    "\n",
    "Another example is customer churn datasets. [Customer churn](https://en.wikipedia.org/wiki/Customer_attrition) refers to the notion of customers leaving a subscription service like Netflix. In this exercise, we will try to predict customer churn in a dataset where most of the customers stay with the service and a small minority cancel their subscription. To start, please download the [Kaggle telecom customer churn dataset](https://www.kaggle.com/becksddf/churn-in-telecoms-dataset). Once you have the data, you should be able to run the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starter code below reads the data CSV as a pandas dataframe and splits it into 70% train and 30% test. \n",
    "\n",
    "Note that `churn` column in the dataset is the target. \"True\" means the customer left the subscription (churned) and \"False\" means they stayed.\n",
    "\n",
    "> Note that for this kind of problem a more appropriate technique is something called survival analysis and we'll be talking about it later in the course. For now, we'll just treat it as a binary classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>NE</td>\n",
       "      <td>70</td>\n",
       "      <td>415</td>\n",
       "      <td>421-8535</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>213.4</td>\n",
       "      <td>86</td>\n",
       "      <td>36.28</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>17.40</td>\n",
       "      <td>256.6</td>\n",
       "      <td>101</td>\n",
       "      <td>11.55</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>WI</td>\n",
       "      <td>67</td>\n",
       "      <td>510</td>\n",
       "      <td>417-2265</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>134</td>\n",
       "      <td>18.55</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>12.10</td>\n",
       "      <td>91.2</td>\n",
       "      <td>86</td>\n",
       "      <td>4.10</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>NJ</td>\n",
       "      <td>122</td>\n",
       "      <td>415</td>\n",
       "      <td>327-9341</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>34</td>\n",
       "      <td>146.4</td>\n",
       "      <td>104</td>\n",
       "      <td>24.89</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>7.62</td>\n",
       "      <td>220.0</td>\n",
       "      <td>91</td>\n",
       "      <td>9.90</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4</td>\n",
       "      <td>4.21</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>NV</td>\n",
       "      <td>107</td>\n",
       "      <td>510</td>\n",
       "      <td>419-9688</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>234.1</td>\n",
       "      <td>91</td>\n",
       "      <td>39.80</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>13.86</td>\n",
       "      <td>282.5</td>\n",
       "      <td>100</td>\n",
       "      <td>12.71</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>HI</td>\n",
       "      <td>105</td>\n",
       "      <td>510</td>\n",
       "      <td>364-8128</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>125.4</td>\n",
       "      <td>116</td>\n",
       "      <td>21.32</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>22.23</td>\n",
       "      <td>241.6</td>\n",
       "      <td>104</td>\n",
       "      <td>10.87</td>\n",
       "      <td>11.4</td>\n",
       "      <td>9</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>WY</td>\n",
       "      <td>126</td>\n",
       "      <td>408</td>\n",
       "      <td>339-9798</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>197.6</td>\n",
       "      <td>126</td>\n",
       "      <td>33.59</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>20.95</td>\n",
       "      <td>285.3</td>\n",
       "      <td>104</td>\n",
       "      <td>12.84</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>WV</td>\n",
       "      <td>70</td>\n",
       "      <td>510</td>\n",
       "      <td>348-3777</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>143.4</td>\n",
       "      <td>72</td>\n",
       "      <td>24.38</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>14.45</td>\n",
       "      <td>127.9</td>\n",
       "      <td>68</td>\n",
       "      <td>5.76</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>NJ</td>\n",
       "      <td>125</td>\n",
       "      <td>415</td>\n",
       "      <td>406-6400</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>182.3</td>\n",
       "      <td>64</td>\n",
       "      <td>30.99</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>11.88</td>\n",
       "      <td>171.6</td>\n",
       "      <td>96</td>\n",
       "      <td>7.72</td>\n",
       "      <td>11.6</td>\n",
       "      <td>7</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>NE</td>\n",
       "      <td>159</td>\n",
       "      <td>415</td>\n",
       "      <td>362-5111</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>189.1</td>\n",
       "      <td>105</td>\n",
       "      <td>32.15</td>\n",
       "      <td>...</td>\n",
       "      <td>147</td>\n",
       "      <td>20.92</td>\n",
       "      <td>242.0</td>\n",
       "      <td>106</td>\n",
       "      <td>10.89</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>PA</td>\n",
       "      <td>106</td>\n",
       "      <td>408</td>\n",
       "      <td>403-9167</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>133.7</td>\n",
       "      <td>45</td>\n",
       "      <td>22.73</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>15.96</td>\n",
       "      <td>181.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.19</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2333 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  account length  area code phone number international plan  \\\n",
       "1402    NE              70        415     421-8535                 no   \n",
       "1855    WI              67        510     417-2265                 no   \n",
       "633     NJ             122        415     327-9341                 no   \n",
       "1483    NV             107        510     419-9688                yes   \n",
       "2638    HI             105        510     364-8128                 no   \n",
       "...    ...             ...        ...          ...                ...   \n",
       "2154    WY             126        408     339-9798                yes   \n",
       "3089    WV              70        510     348-3777                 no   \n",
       "1766    NJ             125        415     406-6400                 no   \n",
       "1122    NE             159        415     362-5111                 no   \n",
       "1346    PA             106        408     403-9167                yes   \n",
       "\n",
       "     voice mail plan  number vmail messages  total day minutes  \\\n",
       "1402              no                      0              213.4   \n",
       "1855              no                      0              109.1   \n",
       "633              yes                     34              146.4   \n",
       "1483              no                      0              234.1   \n",
       "2638              no                      0              125.4   \n",
       "...              ...                    ...                ...   \n",
       "2154              no                      0              197.6   \n",
       "3089             yes                     30              143.4   \n",
       "1766              no                      0              182.3   \n",
       "1122              no                      0              189.1   \n",
       "1346              no                      0              133.7   \n",
       "\n",
       "      total day calls  total day charge  ...  total eve calls  \\\n",
       "1402               86             36.28  ...               77   \n",
       "1855              134             18.55  ...               76   \n",
       "633               104             24.89  ...              103   \n",
       "1483               91             39.80  ...              105   \n",
       "2638              116             21.32  ...               95   \n",
       "...               ...               ...  ...              ...   \n",
       "2154              126             33.59  ...              112   \n",
       "3089               72             24.38  ...               92   \n",
       "1766               64             30.99  ...              121   \n",
       "1122              105             32.15  ...              147   \n",
       "1346               45             22.73  ...              107   \n",
       "\n",
       "      total eve charge  total night minutes  total night calls  \\\n",
       "1402             17.40                256.6                101   \n",
       "1855             12.10                 91.2                 86   \n",
       "633               7.62                220.0                 91   \n",
       "1483             13.86                282.5                100   \n",
       "2638             22.23                241.6                104   \n",
       "...                ...                  ...                ...   \n",
       "2154             20.95                285.3                104   \n",
       "3089             14.45                127.9                 68   \n",
       "1766             11.88                171.6                 96   \n",
       "1122             20.92                242.0                106   \n",
       "1346             15.96                181.9                 89   \n",
       "\n",
       "      total night charge  total intl minutes  total intl calls  \\\n",
       "1402               11.55                 5.7                 4   \n",
       "1855                4.10                10.9                 5   \n",
       "633                 9.90                15.6                 4   \n",
       "1483               12.71                10.0                 3   \n",
       "2638               10.87                11.4                 9   \n",
       "...                  ...                 ...               ...   \n",
       "2154               12.84                12.5                 8   \n",
       "3089                5.76                 9.4                 4   \n",
       "1766                7.72                11.6                 7   \n",
       "1122               10.89                10.4                 5   \n",
       "1346                8.19                10.7                 2   \n",
       "\n",
       "      total intl charge  customer service calls  churn  \n",
       "1402               1.54                       1  False  \n",
       "1855               2.94                       2  False  \n",
       "633                4.21                       2  False  \n",
       "1483               2.70                       1  False  \n",
       "2638               3.08                       2  False  \n",
       "...                 ...                     ...    ...  \n",
       "2154               3.38                       2  False  \n",
       "3089               2.54                       3  False  \n",
       "1766               3.13                       2  False  \n",
       "1122               2.81                       1   True  \n",
       "1346               2.89                       1   True  \n",
       "\n",
       "[2333 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bigml_59c28831336c6604c800002a.csv\", encoding=\"utf-8\")\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Distribution of target values\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Examine the distribution of target values in the train split. Do you see class imbalance? If yes, do we need to deal with it? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    1984\n",
      "True      349\n",
      "Name: churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count the number of True and False values in 'col1'\n",
    "counts = train_df['churn'].value_counts()\n",
    "\n",
    "# print the counts\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the information from value_counts(), we can see that there is a large class imbalance in favor of false in the target values. In some cases, as long as the model performance during prediction is acceptable, we can ignore this class imbalance. However in this case, we should deal with the class imbalance as the minority class \"true\" is of particular interest when it comes to prediction as we want to accurately determine how many customers have left or stayed in the subscription. This means that we should perform some sort of processing to deal with the imbalance, for example weighting or changing the data counts directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 2.2 EDA \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Come up with **two** exploratory questions you would like to answer and explore those. Briefly discuss your results in 1-3 sentences.\n",
    "\n",
    "You are welcome to use `pandas_profiling` (see Lecture 10) but you don't have to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Column transformer \n",
    "rubric={points:14}\n",
    "\n",
    "The code below creates `X_train`, `y_train`, `X_test`, `y_test` for you. \n",
    "In preparation for building a classifier, set up a `ColumnTransformer` that performs whatever feature transformations you deem sensible. This can include dropping features if you think they are not helpful. Remember that by default `ColumnTransformer` will drop any columns that aren't accounted for when it's created.\n",
    "\n",
    "For each group of features (e.g. numeric, categorical or else) explain why you are applying the particular transformation. For example, \"I am doing transformation X to the following categorical features: `a`, `b`, `c` because of reason Y,\" etc.\n",
    "\n",
    "Finally, fit `ColumnTransformer` on your training set; and use the `ColumnTransformer` to transform your train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"churn\"])\n",
    "X_test = test_df.drop(columns=[\"churn\"])\n",
    "\n",
    "y_train = train_df[\"churn\"]\n",
    "y_test = test_df[\"churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2333 entries, 1402 to 1346\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   2333 non-null   object \n",
      " 1   account length          2333 non-null   int64  \n",
      " 2   area code               2333 non-null   int64  \n",
      " 3   phone number            2333 non-null   object \n",
      " 4   international plan      2333 non-null   object \n",
      " 5   voice mail plan         2333 non-null   object \n",
      " 6   number vmail messages   2333 non-null   int64  \n",
      " 7   total day minutes       2333 non-null   float64\n",
      " 8   total day calls         2333 non-null   int64  \n",
      " 9   total day charge        2333 non-null   float64\n",
      " 10  total eve minutes       2333 non-null   float64\n",
      " 11  total eve calls         2333 non-null   int64  \n",
      " 12  total eve charge        2333 non-null   float64\n",
      " 13  total night minutes     2333 non-null   float64\n",
      " 14  total night calls       2333 non-null   int64  \n",
      " 15  total night charge      2333 non-null   float64\n",
      " 16  total intl minutes      2333 non-null   float64\n",
      " 17  total intl calls        2333 non-null   int64  \n",
      " 18  total intl charge       2333 non-null   float64\n",
      " 19  customer service calls  2333 non-null   int64  \n",
      " 20  churn                   2333 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(4)\n",
      "memory usage: 385.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformations:\n",
    "\n",
    "Categorical:\n",
    "\n",
    "State: OHE\n",
    "\n",
    "International Plan: OHE\n",
    "\n",
    "Voice mail plan: OHE\n",
    "\n",
    "Churn: OHE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Numeric:\n",
    "\n",
    "Account Length: scale\n",
    "\n",
    "area code: ? drop\n",
    "\n",
    "phone number: ? drop\n",
    "\n",
    "number vmail messages: scale\n",
    "\n",
    "total day minutes/calls/charge: scale\n",
    "\n",
    "total eve minutes/calls/charge: scale\n",
    "\n",
    "total night minutes/calls/charge: scale\n",
    "\n",
    "total intl minutues/calls/charge: scale\n",
    "\n",
    "customer service calls: nothing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be applying standard scaling to the numeric features because this allows the model to optimize without data points being too far or close together, while also preventing getting caught in local minimas.\n",
    "The numeric features are 'account length', 'number vmail messages', 'total day minutes', 'total day calls', \n",
    "                    'total day charge', 'total eve minutes', 'total eve calls', 'total eve charge',\n",
    "                    'total night minutes', 'total night calls', 'total night charge', 'total intl minutes',\n",
    "                    'total intl calls', 'total intl charge', 'customer service calls'. \n",
    "\n",
    "I will be applying OHE to categorical features as this converts data into numerical format. 'state', 'area code', 'international plan', 'voice mail plan'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"account length\", \"number vmail messages\", \"total day calls\",\"total day minutes\", \"total day charge\", \"total eve calls\",\"total eve minutes\", \"total eve charge\", \"total night calls\",\"total night minutes\", \"total night charge\",\"total intl calls\",\"total intl minutes\", \"total intl charge\", \"customer service calls\"]\n",
    "categorical_features = [\"state\", \"international plan\", \"voice mail plan\", \"area code\"]\n",
    "drop_features = [\"phone number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from lecture 11\n",
    "\n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = preprocessor.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 area code feature\n",
    "rubric={points:4}\n",
    "\n",
    "The original dataset had a feature called `area code`.\n",
    "\n",
    "1. The area codes are numbers. Does it make sense to encode them as one-hot-endoded (OHE) or not? Please justify your response.\n",
    "2. What were the possible values of `area code`? \n",
    "3. If area code is encoded with OHE, how many new features are created to replace it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415    1178\n",
      "408     588\n",
      "510     567\n",
      "Name: area code, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = train_df['area code'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "1. Yes, OHE would be preferred in this case as area code is the direct numeric representation of different area codes. This would allow for the encoding to be reduced to smaller integers which is a more interpretable format and convenient in our case since there is only 3 possible area codes. \n",
    "\n",
    "2. What were the possible values of `area code`?  \n",
    "\n",
    "    415, 408, 510\n",
    "\n",
    "\n",
    "3. \n",
    "Only three new features would need to be created to replace the area code feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Logistic regression\n",
    "rubric={points:12} \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Report the cross-validation results of a `LogisticRegression` model, with default Hparams, on the following metrics: `\"accuracy\", \"precision\", \"recall\", \"f1\"`\n",
    "2. Are you satisfied with the results? Explain why or why not. Discuss in a few sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088992</td>\n",
       "      <td>0.019079</td>\n",
       "      <td>0.867238</td>\n",
       "      <td>0.864416</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.335958</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.229391</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.106152</td>\n",
       "      <td>0.019557</td>\n",
       "      <td>0.854390</td>\n",
       "      <td>0.868703</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.370180</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.654545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056327</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.372449</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.261649</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.646018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055108</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.869099</td>\n",
       "      <td>0.866095</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.362245</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.253571</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.633929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.054429</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.869845</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.378517</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.265233</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.660714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  0.088992    0.019079       0.867238        0.864416  0.367347  0.335958   \n",
       "1  0.106152    0.019557       0.854390        0.868703  0.291667  0.370180   \n",
       "2  0.056327    0.012893       0.850107        0.868167  0.255319  0.372449   \n",
       "3  0.055108    0.010945       0.869099        0.866095  0.371134  0.362245   \n",
       "4  0.054429    0.011075       0.836910        0.869845  0.240000  0.378517   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.257143      0.229391        0.642857         0.627451  \n",
       "1     0.200000      0.258065        0.538462         0.654545  \n",
       "2     0.171429      0.261649        0.500000         0.646018  \n",
       "3     0.260870      0.253571        0.642857         0.633929  \n",
       "4     0.171429      0.265233        0.400000         0.660714  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from chapter 9\n",
    "scoring = [\n",
    "    \"accuracy\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "]\n",
    "pipe_lr = make_pipeline(preprocessor, LogisticRegression())\n",
    "\n",
    "scores = cross_validate(\n",
    "    pipe_lr, X_train, y_train, return_train_score=True, scoring=scoring\n",
    ")\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. No. Although fitting and scoring times are not unreasonable and there should be very little overfitting occurring. Precision is relatively low meaning that of the predicted positive examples, many were false positive errors. Recall being low as well means that of all positive examples, only about 23-27% were correctly predicted in the training set, with a lower range present in the test set. Both these metrics are combined in an F1 score that is relatively low for both the training and test sets. These metrics suggest that our model is not preforming well in correctly predicting positive examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Logistic regression with `class_weight`\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Set the `class_weight` parameter of your logistic regression model to `'balanced'` and report the same metrics as in the previous part. \n",
    "2. Do you prefer this model to the one in the previous part? Discuss your results in a few sentences while comparing the metrics of this model and the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213054</td>\n",
       "      <td>0.031305</td>\n",
       "      <td>0.785867</td>\n",
       "      <td>0.769025</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.497083</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.368512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108826</td>\n",
       "      <td>0.013225</td>\n",
       "      <td>0.770878</td>\n",
       "      <td>0.769025</td>\n",
       "      <td>0.492891</td>\n",
       "      <td>0.499419</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.770609</td>\n",
       "      <td>0.368794</td>\n",
       "      <td>0.369416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065669</td>\n",
       "      <td>0.011548</td>\n",
       "      <td>0.764454</td>\n",
       "      <td>0.773848</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.510441</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.788530</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.377358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.066897</td>\n",
       "      <td>0.011745</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.780932</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.520516</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.387435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>0.731760</td>\n",
       "      <td>0.785753</td>\n",
       "      <td>0.434389</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.317881</td>\n",
       "      <td>0.394046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  0.213054    0.031305       0.785867        0.769025  0.489796  0.497083   \n",
       "1  0.108826    0.013225       0.770878        0.769025  0.492891  0.499419   \n",
       "2  0.065669    0.011548       0.764454        0.773848  0.455446  0.510441   \n",
       "3  0.066897    0.011745       0.751073        0.780932  0.462963  0.520516   \n",
       "4  0.075960    0.011686       0.731760        0.785753  0.434389  0.529412   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.685714      0.763441        0.380952         0.368512  \n",
       "1     0.742857      0.770609        0.368794         0.369416  \n",
       "2     0.657143      0.788530        0.348485         0.377358  \n",
       "3     0.724638      0.792857        0.340136         0.387435  \n",
       "4     0.685714      0.806452        0.317881         0.394046  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from chapter 9\n",
    "\n",
    "pipe_lr_balanced = make_pipeline(preprocessor, LogisticRegression(max_iter = 1000, class_weight = 'balanced'))\n",
    "\n",
    "scores_balanced = cross_validate(\n",
    "    pipe_lr_balanced, X_train, y_train, return_train_score=True, scoring=scoring\n",
    ")\n",
    "\n",
    "pd.DataFrame(scores_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Yes, the improved recall scores and associated f1 score increase suggest that addressing the class imbalance in the data was able to improve the predictive performance of our model. However, precision scores on both the test and training set decreased compared to the unbalanced Logistical Regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Hyperparameter optimization\n",
    "rubric={points:10}\n",
    "\n",
    "1. Jointly optimize `C` and `class_weight` with `GridSearchCV` and `scoring=\"f1\"`.\n",
    "  - For `class_weight`, consider 3 values: \n",
    "    - `None` (no weight)\n",
    "    - \"weight of class 0 = 1\"  and  \"weight of class 1 = 3\"\n",
    "    - '`balanced`'\n",
    "  - For `C`, choose some reasonable values\n",
    "2. What values of `C` and `class_weight` are chosen and what is the best cross-validation f1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'logisticregression__class_weight': [None, {0:1, 1:3}, 'balanced'], \n",
    "    'logisticregression__C': 10.0 ** np.arange(-2, 2, 0.5), #try with -2,2,0.5\n",
    "}\n",
    "\n",
    "pipe_lr_max_iter = make_pipeline(preprocessor, LogisticRegression(max_iter=10000))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.31622776601683794, 'logisticregression__class_weight': {0: 1, 1: 3}}\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    pipe_lr_max_iter, param_grid, cv=5, n_jobs=-1, return_train_score = True, scoring=\"f1\"\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "# grid_search.best_score_\n",
    "print(grid_search.best_params_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.921563</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.468293</td>\n",
       "      <td>0.494279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.407312</td>\n",
       "      <td>0.009396</td>\n",
       "      <td>0.504587</td>\n",
       "      <td>0.485682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.417063</td>\n",
       "      <td>0.009045</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.531108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.600577</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.538226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.090638</td>\n",
       "      <td>0.011183</td>\n",
       "      <td>0.453488</td>\n",
       "      <td>0.535604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  6.921563    0.010417    0.468293     0.494279\n",
       "1  8.407312    0.009396    0.504587     0.485682\n",
       "2  8.417063    0.009045    0.428571     0.531108\n",
       "3  7.600577    0.008257    0.478528     0.538226\n",
       "4  8.090638    0.011183    0.453488     0.535604"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_grid = cross_validate(\n",
    "    grid_search, X_train, y_train, return_train_score=True, scoring=\"f1\"\n",
    ")\n",
    "\n",
    "\n",
    "pd.DataFrame(scores_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank_test_score</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.120863</td>\n",
       "      <td>0.096866</td>\n",
       "      <td>0.278745</td>\n",
       "      <td>0.111344</td>\n",
       "      <td>0.447519</td>\n",
       "      <td>0.17315</td>\n",
       "      <td>0.273014</td>\n",
       "      <td>0.221761</td>\n",
       "      <td>0.119802</td>\n",
       "      <td>0.099035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187289</td>\n",
       "      <td>0.111155</td>\n",
       "      <td>0.280032</td>\n",
       "      <td>0.174548</td>\n",
       "      <td>0.331959</td>\n",
       "      <td>0.143297</td>\n",
       "      <td>0.105073</td>\n",
       "      <td>0.078422</td>\n",
       "      <td>0.077824</td>\n",
       "      <td>0.084069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>0.11788</td>\n",
       "      <td>0.025087</td>\n",
       "      <td>0.123602</td>\n",
       "      <td>0.042013</td>\n",
       "      <td>0.055543</td>\n",
       "      <td>0.030807</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02053</td>\n",
       "      <td>0.029043</td>\n",
       "      <td>0.082929</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>0.080696</td>\n",
       "      <td>0.047434</td>\n",
       "      <td>0.017594</td>\n",
       "      <td>0.013864</td>\n",
       "      <td>0.013572</td>\n",
       "      <td>0.028367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.017254</td>\n",
       "      <td>0.016698</td>\n",
       "      <td>0.056499</td>\n",
       "      <td>0.026246</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>0.028075</td>\n",
       "      <td>0.023703</td>\n",
       "      <td>0.022062</td>\n",
       "      <td>0.018953</td>\n",
       "      <td>0.023059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023394</td>\n",
       "      <td>0.036605</td>\n",
       "      <td>0.016388</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.021219</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>0.025194</td>\n",
       "      <td>0.024228</td>\n",
       "      <td>0.018232</td>\n",
       "      <td>0.046372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>0.06695</td>\n",
       "      <td>0.010348</td>\n",
       "      <td>0.009308</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>0.023887</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.01019</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>0.009151</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.057999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>31.622777</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>31.622777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_logisticregression__class_weight</th>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "      <td>balanced</td>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "      <td>balanced</td>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>...</td>\n",
       "      <td>balanced</td>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'logisticregression__C': 0.31622776601683794,...</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>{'logisticregression__C': 1.0, 'logisticregres...</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>{'logisticregression__C': 10.0, 'logisticregre...</td>\n",
       "      <td>{'logisticregression__C': 0.03162277660168379,...</td>\n",
       "      <td>{'logisticregression__C': 31.622776601683793, ...</td>\n",
       "      <td>{'logisticregression__C': 3.1622776601683795, ...</td>\n",
       "      <td>{'logisticregression__C': 0.31622776601683794,...</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'logisticregression__C': 3.1622776601683795, ...</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "      <td>{'logisticregression__C': 10.0, 'logisticregre...</td>\n",
       "      <td>{'logisticregression__C': 3.1622776601683795, ...</td>\n",
       "      <td>{'logisticregression__C': 31.622776601683793, ...</td>\n",
       "      <td>{'logisticregression__C': 1.0, 'logisticregres...</td>\n",
       "      <td>{'logisticregression__C': 0.31622776601683794,...</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>{'logisticregression__C': 0.03162277660168379,...</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.524823</td>\n",
       "      <td>0.546763</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.521127</td>\n",
       "      <td>0.468293</td>\n",
       "      <td>0.521127</td>\n",
       "      <td>0.521127</td>\n",
       "      <td>0.484536</td>\n",
       "      <td>0.481132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479592</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.054795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.552147</td>\n",
       "      <td>0.54321</td>\n",
       "      <td>0.495327</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.504587</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.540881</td>\n",
       "      <td>0.497653</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488038</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.30303</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.027397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.427673</td>\n",
       "      <td>0.478049</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.468293</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.42236</td>\n",
       "      <td>0.465347</td>\n",
       "      <td>0.465347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.403101</td>\n",
       "      <td>0.252632</td>\n",
       "      <td>0.252632</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.26087</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.106667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.466258</td>\n",
       "      <td>0.45509</td>\n",
       "      <td>0.477477</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.469027</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.450216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453704</td>\n",
       "      <td>0.457516</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.368932</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.109589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.445783</td>\n",
       "      <td>0.453488</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.434286</td>\n",
       "      <td>0.480349</td>\n",
       "      <td>0.429379</td>\n",
       "      <td>0.44186</td>\n",
       "      <td>0.436681</td>\n",
       "      <td>0.471616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.280374</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.236559</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.028169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.491753</td>\n",
       "      <td>0.486697</td>\n",
       "      <td>0.481606</td>\n",
       "      <td>0.481274</td>\n",
       "      <td>0.478599</td>\n",
       "      <td>0.47811</td>\n",
       "      <td>0.477618</td>\n",
       "      <td>0.477553</td>\n",
       "      <td>0.470961</td>\n",
       "      <td>0.470091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460981</td>\n",
       "      <td>0.442918</td>\n",
       "      <td>0.314864</td>\n",
       "      <td>0.310324</td>\n",
       "      <td>0.309276</td>\n",
       "      <td>0.305093</td>\n",
       "      <td>0.287234</td>\n",
       "      <td>0.274248</td>\n",
       "      <td>0.201308</td>\n",
       "      <td>0.065323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.045509</td>\n",
       "      <td>0.053104</td>\n",
       "      <td>0.045614</td>\n",
       "      <td>0.010457</td>\n",
       "      <td>0.053088</td>\n",
       "      <td>0.014009</td>\n",
       "      <td>0.053936</td>\n",
       "      <td>0.045795</td>\n",
       "      <td>0.020511</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019334</td>\n",
       "      <td>0.029085</td>\n",
       "      <td>0.045449</td>\n",
       "      <td>0.045485</td>\n",
       "      <td>0.050331</td>\n",
       "      <td>0.055012</td>\n",
       "      <td>0.051225</td>\n",
       "      <td>0.05871</td>\n",
       "      <td>0.063775</td>\n",
       "      <td>0.036327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.504644</td>\n",
       "      <td>0.494453</td>\n",
       "      <td>0.504587</td>\n",
       "      <td>0.498845</td>\n",
       "      <td>0.506829</td>\n",
       "      <td>0.494279</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.507599</td>\n",
       "      <td>0.498254</td>\n",
       "      <td>0.479911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498262</td>\n",
       "      <td>0.447552</td>\n",
       "      <td>0.351421</td>\n",
       "      <td>0.34715</td>\n",
       "      <td>0.357513</td>\n",
       "      <td>0.335958</td>\n",
       "      <td>0.318059</td>\n",
       "      <td>0.265537</td>\n",
       "      <td>0.167702</td>\n",
       "      <td>0.061856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.523659</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.520376</td>\n",
       "      <td>0.497674</td>\n",
       "      <td>0.528594</td>\n",
       "      <td>0.485682</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.498829</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506944</td>\n",
       "      <td>0.467257</td>\n",
       "      <td>0.377551</td>\n",
       "      <td>0.377551</td>\n",
       "      <td>0.380711</td>\n",
       "      <td>0.37018</td>\n",
       "      <td>0.360313</td>\n",
       "      <td>0.321716</td>\n",
       "      <td>0.240469</td>\n",
       "      <td>0.081633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.531108</td>\n",
       "      <td>0.51944</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.511521</td>\n",
       "      <td>0.537538</td>\n",
       "      <td>0.494279</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.538346</td>\n",
       "      <td>0.517401</td>\n",
       "      <td>0.481356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513419</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.37931</td>\n",
       "      <td>0.382134</td>\n",
       "      <td>0.386308</td>\n",
       "      <td>0.372449</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.313187</td>\n",
       "      <td>0.23494</td>\n",
       "      <td>0.075342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>0.538226</td>\n",
       "      <td>0.524031</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.515081</td>\n",
       "      <td>0.536364</td>\n",
       "      <td>0.493656</td>\n",
       "      <td>0.537764</td>\n",
       "      <td>0.534954</td>\n",
       "      <td>0.519389</td>\n",
       "      <td>0.484091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523754</td>\n",
       "      <td>0.480274</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.349367</td>\n",
       "      <td>0.352645</td>\n",
       "      <td>0.362245</td>\n",
       "      <td>0.349869</td>\n",
       "      <td>0.319783</td>\n",
       "      <td>0.193353</td>\n",
       "      <td>0.07483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>0.528951</td>\n",
       "      <td>0.513557</td>\n",
       "      <td>0.535604</td>\n",
       "      <td>0.516432</td>\n",
       "      <td>0.557078</td>\n",
       "      <td>0.499422</td>\n",
       "      <td>0.559271</td>\n",
       "      <td>0.550769</td>\n",
       "      <td>0.524203</td>\n",
       "      <td>0.484501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530035</td>\n",
       "      <td>0.482639</td>\n",
       "      <td>0.409877</td>\n",
       "      <td>0.406015</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.378517</td>\n",
       "      <td>0.341207</td>\n",
       "      <td>0.312668</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.087248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.525318</td>\n",
       "      <td>0.51286</td>\n",
       "      <td>0.525813</td>\n",
       "      <td>0.507911</td>\n",
       "      <td>0.53328</td>\n",
       "      <td>0.493464</td>\n",
       "      <td>0.535216</td>\n",
       "      <td>0.531597</td>\n",
       "      <td>0.511615</td>\n",
       "      <td>0.479799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.473504</td>\n",
       "      <td>0.373329</td>\n",
       "      <td>0.372443</td>\n",
       "      <td>0.378769</td>\n",
       "      <td>0.36387</td>\n",
       "      <td>0.342855</td>\n",
       "      <td>0.306578</td>\n",
       "      <td>0.208011</td>\n",
       "      <td>0.076182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.011345</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>0.012077</td>\n",
       "      <td>0.00805</td>\n",
       "      <td>0.016221</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.016308</td>\n",
       "      <td>0.01434</td>\n",
       "      <td>0.010903</td>\n",
       "      <td>0.005598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>0.02294</td>\n",
       "      <td>0.014897</td>\n",
       "      <td>0.013967</td>\n",
       "      <td>0.020826</td>\n",
       "      <td>0.026974</td>\n",
       "      <td>0.008485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "rank_test_score                                                                        1   \\\n",
       "mean_fit_time                                                                    0.120863   \n",
       "std_fit_time                                                                     0.009233   \n",
       "mean_score_time                                                                  0.017254   \n",
       "std_score_time                                                                   0.004155   \n",
       "param_logisticregression__C                                                      0.316228   \n",
       "param_logisticregression__class_weight                                       {0: 1, 1: 3}   \n",
       "params                                  {'logisticregression__C': 0.31622776601683794,...   \n",
       "split0_test_score                                                                0.524823   \n",
       "split1_test_score                                                                0.559006   \n",
       "split2_test_score                                                                0.428571   \n",
       "split3_test_score                                                                0.478528   \n",
       "split4_test_score                                                                0.467836   \n",
       "mean_test_score                                                                  0.491753   \n",
       "std_test_score                                                                   0.045509   \n",
       "split0_train_score                                                               0.504644   \n",
       "split1_train_score                                                               0.523659   \n",
       "split2_train_score                                                               0.531108   \n",
       "split3_train_score                                                               0.538226   \n",
       "split4_train_score                                                               0.528951   \n",
       "mean_train_score                                                                 0.525318   \n",
       "std_train_score                                                                  0.011345   \n",
       "\n",
       "rank_test_score                                                                        2   \\\n",
       "mean_fit_time                                                                    0.096866   \n",
       "std_fit_time                                                                     0.009025   \n",
       "mean_score_time                                                                  0.016698   \n",
       "std_score_time                                                                   0.004526   \n",
       "param_logisticregression__C                                                           0.1   \n",
       "param_logisticregression__class_weight                                       {0: 1, 1: 3}   \n",
       "params                                  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "split0_test_score                                                                0.546763   \n",
       "split1_test_score                                                                0.552147   \n",
       "split2_test_score                                                                0.422535   \n",
       "split3_test_score                                                                0.466258   \n",
       "split4_test_score                                                                0.445783   \n",
       "mean_test_score                                                                  0.486697   \n",
       "std_test_score                                                                   0.053104   \n",
       "split0_train_score                                                               0.494453   \n",
       "split1_train_score                                                               0.512821   \n",
       "split2_train_score                                                                0.51944   \n",
       "split3_train_score                                                               0.524031   \n",
       "split4_train_score                                                               0.513557   \n",
       "mean_train_score                                                                  0.51286   \n",
       "std_train_score                                                                  0.010074   \n",
       "\n",
       "rank_test_score                                                                        3   \\\n",
       "mean_fit_time                                                                    0.278745   \n",
       "std_fit_time                                                                      0.11788   \n",
       "mean_score_time                                                                  0.056499   \n",
       "std_score_time                                                                    0.06695   \n",
       "param_logisticregression__C                                                           1.0   \n",
       "param_logisticregression__class_weight                                       {0: 1, 1: 3}   \n",
       "params                                  {'logisticregression__C': 1.0, 'logisticregres...   \n",
       "split0_test_score                                                                0.528571   \n",
       "split1_test_score                                                                 0.54321   \n",
       "split2_test_score                                                                0.427673   \n",
       "split3_test_score                                                                 0.45509   \n",
       "split4_test_score                                                                0.453488   \n",
       "mean_test_score                                                                  0.481606   \n",
       "std_test_score                                                                   0.045614   \n",
       "split0_train_score                                                               0.504587   \n",
       "split1_train_score                                                               0.520376   \n",
       "split2_train_score                                                               0.531915   \n",
       "split3_train_score                                                               0.536585   \n",
       "split4_train_score                                                               0.535604   \n",
       "mean_train_score                                                                 0.525813   \n",
       "std_train_score                                                                  0.012077   \n",
       "\n",
       "rank_test_score                                                                        4   \\\n",
       "mean_fit_time                                                                    0.111344   \n",
       "std_fit_time                                                                     0.025087   \n",
       "mean_score_time                                                                  0.026246   \n",
       "std_score_time                                                                   0.010348   \n",
       "param_logisticregression__C                                                           0.1   \n",
       "param_logisticregression__class_weight                                           balanced   \n",
       "params                                  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "split0_test_score                                                                    0.49   \n",
       "split1_test_score                                                                0.495327   \n",
       "split2_test_score                                                                0.478049   \n",
       "split3_test_score                                                                0.477477   \n",
       "split4_test_score                                                                0.465517   \n",
       "mean_test_score                                                                  0.481274   \n",
       "std_test_score                                                                   0.010457   \n",
       "split0_train_score                                                               0.498845   \n",
       "split1_train_score                                                               0.497674   \n",
       "split2_train_score                                                               0.511521   \n",
       "split3_train_score                                                               0.515081   \n",
       "split4_train_score                                                               0.516432   \n",
       "mean_train_score                                                                 0.507911   \n",
       "std_train_score                                                                   0.00805   \n",
       "\n",
       "rank_test_score                                                                        5   \\\n",
       "mean_fit_time                                                                    0.447519   \n",
       "std_fit_time                                                                     0.123602   \n",
       "mean_score_time                                                                  0.022044   \n",
       "std_score_time                                                                   0.009308   \n",
       "param_logisticregression__C                                                          10.0   \n",
       "param_logisticregression__class_weight                                       {0: 1, 1: 3}   \n",
       "params                                  {'logisticregression__C': 10.0, 'logisticregre...   \n",
       "split0_test_score                                                                0.521127   \n",
       "split1_test_score                                                                0.559006   \n",
       "split2_test_score                                                                0.419753   \n",
       "split3_test_score                                                                0.458824   \n",
       "split4_test_score                                                                0.434286   \n",
       "mean_test_score                                                                  0.478599   \n",
       "std_test_score                                                                   0.053088   \n",
       "split0_train_score                                                               0.506829   \n",
       "split1_train_score                                                               0.528594   \n",
       "split2_train_score                                                               0.537538   \n",
       "split3_train_score                                                               0.536364   \n",
       "split4_train_score                                                               0.557078   \n",
       "mean_train_score                                                                  0.53328   \n",
       "std_train_score                                                                  0.016221   \n",
       "\n",
       "rank_test_score                                                                        6   \\\n",
       "mean_fit_time                                                                     0.17315   \n",
       "std_fit_time                                                                     0.042013   \n",
       "mean_score_time                                                                  0.028075   \n",
       "std_score_time                                                                   0.010623   \n",
       "param_logisticregression__C                                                      0.031623   \n",
       "param_logisticregression__class_weight                                           balanced   \n",
       "params                                  {'logisticregression__C': 0.03162277660168379,...   \n",
       "split0_test_score                                                                0.468293   \n",
       "split1_test_score                                                                0.504587   \n",
       "split2_test_score                                                                0.468293   \n",
       "split3_test_score                                                                0.469027   \n",
       "split4_test_score                                                                0.480349   \n",
       "mean_test_score                                                                   0.47811   \n",
       "std_test_score                                                                   0.014009   \n",
       "split0_train_score                                                               0.494279   \n",
       "split1_train_score                                                               0.485682   \n",
       "split2_train_score                                                               0.494279   \n",
       "split3_train_score                                                               0.493656   \n",
       "split4_train_score                                                               0.499422   \n",
       "mean_train_score                                                                 0.493464   \n",
       "std_train_score                                                                  0.004414   \n",
       "\n",
       "rank_test_score                                                                        7   \\\n",
       "mean_fit_time                                                                    0.273014   \n",
       "std_fit_time                                                                     0.055543   \n",
       "mean_score_time                                                                  0.023703   \n",
       "std_score_time                                                                   0.006617   \n",
       "param_logisticregression__C                                                     31.622777   \n",
       "param_logisticregression__class_weight                                       {0: 1, 1: 3}   \n",
       "params                                  {'logisticregression__C': 31.622776601683793, ...   \n",
       "split0_test_score                                                                0.521127   \n",
       "split1_test_score                                                                0.559006   \n",
       "split2_test_score                                                                0.419753   \n",
       "split3_test_score                                                                0.458824   \n",
       "split4_test_score                                                                0.429379   \n",
       "mean_test_score                                                                  0.477618   \n",
       "std_test_score                                                                   0.053936   \n",
       "split0_train_score                                                               0.509091   \n",
       "split1_train_score                                                               0.529412   \n",
       "split2_train_score                                                               0.540541   \n",
       "split3_train_score                                                               0.537764   \n",
       "split4_train_score                                                               0.559271   \n",
       "mean_train_score                                                                 0.535216   \n",
       "std_train_score                                                                  0.016308   \n",
       "\n",
       "rank_test_score                                                                        8   \\\n",
       "mean_fit_time                                                                    0.221761   \n",
       "std_fit_time                                                                     0.030807   \n",
       "mean_score_time                                                                  0.022062   \n",
       "std_score_time                                                                   0.006013   \n",
       "param_logisticregression__C                                                      3.162278   \n",
       "param_logisticregression__class_weight                                       {0: 1, 1: 3}   \n",
       "params                                  {'logisticregression__C': 3.1622776601683795, ...   \n",
       "split0_test_score                                                                0.521127   \n",
       "split1_test_score                                                                0.540881   \n",
       "split2_test_score                                                                 0.42236   \n",
       "split3_test_score                                                                0.461538   \n",
       "split4_test_score                                                                 0.44186   \n",
       "mean_test_score                                                                  0.477553   \n",
       "std_test_score                                                                   0.045795   \n",
       "split0_train_score                                                               0.507599   \n",
       "split1_train_score                                                               0.526316   \n",
       "split2_train_score                                                               0.538346   \n",
       "split3_train_score                                                               0.534954   \n",
       "split4_train_score                                                               0.550769   \n",
       "mean_train_score                                                                 0.531597   \n",
       "std_train_score                                                                   0.01434   \n",
       "\n",
       "rank_test_score                                                                        9   \\\n",
       "mean_fit_time                                                                    0.119802   \n",
       "std_fit_time                                                                     0.005185   \n",
       "mean_score_time                                                                  0.018953   \n",
       "std_score_time                                                                   0.006159   \n",
       "param_logisticregression__C                                                      0.316228   \n",
       "param_logisticregression__class_weight                                           balanced   \n",
       "params                                  {'logisticregression__C': 0.31622776601683794,...   \n",
       "split0_test_score                                                                0.484536   \n",
       "split1_test_score                                                                0.497653   \n",
       "split2_test_score                                                                0.465347   \n",
       "split3_test_score                                                                0.470588   \n",
       "split4_test_score                                                                0.436681   \n",
       "mean_test_score                                                                  0.470961   \n",
       "std_test_score                                                                   0.020511   \n",
       "split0_train_score                                                               0.498254   \n",
       "split1_train_score                                                               0.498829   \n",
       "split2_train_score                                                               0.517401   \n",
       "split3_train_score                                                               0.519389   \n",
       "split4_train_score                                                               0.524203   \n",
       "mean_train_score                                                                 0.511615   \n",
       "std_train_score                                                                  0.010903   \n",
       "\n",
       "rank_test_score                                                                        10  \\\n",
       "mean_fit_time                                                                    0.099035   \n",
       "std_fit_time                                                                     0.013135   \n",
       "mean_score_time                                                                  0.023059   \n",
       "std_score_time                                                                   0.008473   \n",
       "param_logisticregression__C                                                          0.01   \n",
       "param_logisticregression__class_weight                                           balanced   \n",
       "params                                  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "split0_test_score                                                                0.481132   \n",
       "split1_test_score                                                                0.482143   \n",
       "split2_test_score                                                                0.465347   \n",
       "split3_test_score                                                                0.450216   \n",
       "split4_test_score                                                                0.471616   \n",
       "mean_test_score                                                                  0.470091   \n",
       "std_test_score                                                                   0.011722   \n",
       "split0_train_score                                                               0.479911   \n",
       "split1_train_score                                                               0.469136   \n",
       "split2_train_score                                                               0.481356   \n",
       "split3_train_score                                                               0.484091   \n",
       "split4_train_score                                                               0.484501   \n",
       "mean_train_score                                                                 0.479799   \n",
       "std_train_score                                                                  0.005598   \n",
       "\n",
       "rank_test_score                         ...  \\\n",
       "mean_fit_time                           ...   \n",
       "std_fit_time                            ...   \n",
       "mean_score_time                         ...   \n",
       "std_score_time                          ...   \n",
       "param_logisticregression__C             ...   \n",
       "param_logisticregression__class_weight  ...   \n",
       "params                                  ...   \n",
       "split0_test_score                       ...   \n",
       "split1_test_score                       ...   \n",
       "split2_test_score                       ...   \n",
       "split3_test_score                       ...   \n",
       "split4_test_score                       ...   \n",
       "mean_test_score                         ...   \n",
       "std_test_score                          ...   \n",
       "split0_train_score                      ...   \n",
       "split1_train_score                      ...   \n",
       "split2_train_score                      ...   \n",
       "split3_train_score                      ...   \n",
       "split4_train_score                      ...   \n",
       "mean_train_score                        ...   \n",
       "std_train_score                         ...   \n",
       "\n",
       "rank_test_score                                                                        15  \\\n",
       "mean_fit_time                                                                    0.187289   \n",
       "std_fit_time                                                                      0.02053   \n",
       "mean_score_time                                                                  0.023394   \n",
       "std_score_time                                                                   0.007431   \n",
       "param_logisticregression__C                                                      3.162278   \n",
       "param_logisticregression__class_weight                                           balanced   \n",
       "params                                  {'logisticregression__C': 3.1622776601683795, ...   \n",
       "split0_test_score                                                                0.479592   \n",
       "split1_test_score                                                                0.488038   \n",
       "split2_test_score                                                                0.441176   \n",
       "split3_test_score                                                                0.453704   \n",
       "split4_test_score                                                                0.442396   \n",
       "mean_test_score                                                                  0.460981   \n",
       "std_test_score                                                                   0.019334   \n",
       "split0_train_score                                                               0.498262   \n",
       "split1_train_score                                                               0.506944   \n",
       "split2_train_score                                                               0.513419   \n",
       "split3_train_score                                                               0.523754   \n",
       "split4_train_score                                                               0.530035   \n",
       "mean_train_score                                                                 0.514483   \n",
       "std_train_score                                                                  0.011392   \n",
       "\n",
       "rank_test_score                                                                        16  \\\n",
       "mean_fit_time                                                                    0.111155   \n",
       "std_fit_time                                                                     0.029043   \n",
       "mean_score_time                                                                  0.036605   \n",
       "std_score_time                                                                   0.023887   \n",
       "param_logisticregression__C                                                          0.01   \n",
       "param_logisticregression__class_weight                                       {0: 1, 1: 3}   \n",
       "params                                  {'logisticregression__C': 0.01, 'logisticregre...   \n",
       "split0_test_score                                                                0.465116   \n",
       "split1_test_score                                                                0.475524   \n",
       "split2_test_score                                                                0.403101   \n",
       "split3_test_score                                                                0.457516   \n",
       "split4_test_score                                                                0.413333   \n",
       "mean_test_score                                                                  0.442918   \n",
       "std_test_score                                                                   0.029085   \n",
       "split0_train_score                                                               0.447552   \n",
       "split1_train_score                                                               0.467257   \n",
       "split2_train_score                                                               0.489796   \n",
       "split3_train_score                                                               0.480274   \n",
       "split4_train_score                                                               0.482639   \n",
       "mean_train_score                                                                 0.473504   \n",
       "std_train_score                                                                  0.014881   \n",
       "\n",
       "rank_test_score                                                                        17  \\\n",
       "mean_fit_time                                                                    0.280032   \n",
       "std_fit_time                                                                     0.082929   \n",
       "mean_score_time                                                                  0.016388   \n",
       "std_score_time                                                                   0.005113   \n",
       "param_logisticregression__C                                                          10.0   \n",
       "param_logisticregression__class_weight                                               None   \n",
       "params                                  {'logisticregression__C': 10.0, 'logisticregre...   \n",
       "split0_test_score                                                                    0.36   \n",
       "split1_test_score                                                                0.306122   \n",
       "split2_test_score                                                                0.252632   \n",
       "split3_test_score                                                                0.372549   \n",
       "split4_test_score                                                                0.283019   \n",
       "mean_test_score                                                                  0.314864   \n",
       "std_test_score                                                                   0.045449   \n",
       "split0_train_score                                                               0.351421   \n",
       "split1_train_score                                                               0.377551   \n",
       "split2_train_score                                                                0.37931   \n",
       "split3_train_score                                                               0.348485   \n",
       "split4_train_score                                                               0.409877   \n",
       "mean_train_score                                                                 0.373329   \n",
       "std_train_score                                                                    0.0223   \n",
       "\n",
       "rank_test_score                                                                        18  \\\n",
       "mean_fit_time                                                                    0.174548   \n",
       "std_fit_time                                                                     0.010956   \n",
       "mean_score_time                                                                   0.02381   \n",
       "std_score_time                                                                   0.006284   \n",
       "param_logisticregression__C                                                      3.162278   \n",
       "param_logisticregression__class_weight                                               None   \n",
       "params                                  {'logisticregression__C': 3.1622776601683795, ...   \n",
       "split0_test_score                                                                    0.36   \n",
       "split1_test_score                                                                0.306122   \n",
       "split2_test_score                                                                0.252632   \n",
       "split3_test_score                                                                0.363636   \n",
       "split4_test_score                                                                0.269231   \n",
       "mean_test_score                                                                  0.310324   \n",
       "std_test_score                                                                   0.045485   \n",
       "split0_train_score                                                                0.34715   \n",
       "split1_train_score                                                               0.377551   \n",
       "split2_train_score                                                               0.382134   \n",
       "split3_train_score                                                               0.349367   \n",
       "split4_train_score                                                               0.406015   \n",
       "mean_train_score                                                                 0.372443   \n",
       "std_train_score                                                                  0.021997   \n",
       "\n",
       "rank_test_score                                                                        19  \\\n",
       "mean_fit_time                                                                    0.331959   \n",
       "std_fit_time                                                                     0.080696   \n",
       "mean_score_time                                                                  0.021219   \n",
       "std_score_time                                                                    0.01019   \n",
       "param_logisticregression__C                                                     31.622777   \n",
       "param_logisticregression__class_weight                                               None   \n",
       "params                                  {'logisticregression__C': 31.622776601683793, ...   \n",
       "split0_test_score                                                                    0.36   \n",
       "split1_test_score                                                                 0.30303   \n",
       "split2_test_score                                                                0.234043   \n",
       "split3_test_score                                                                0.368932   \n",
       "split4_test_score                                                                0.280374   \n",
       "mean_test_score                                                                  0.309276   \n",
       "std_test_score                                                                   0.050331   \n",
       "split0_train_score                                                               0.357513   \n",
       "split1_train_score                                                               0.380711   \n",
       "split2_train_score                                                               0.386308   \n",
       "split3_train_score                                                               0.352645   \n",
       "split4_train_score                                                               0.416667   \n",
       "mean_train_score                                                                 0.378769   \n",
       "std_train_score                                                                   0.02294   \n",
       "\n",
       "rank_test_score                                                                        20  \\\n",
       "mean_fit_time                                                                    0.143297   \n",
       "std_fit_time                                                                     0.047434   \n",
       "mean_score_time                                                                  0.016771   \n",
       "std_score_time                                                                   0.005127   \n",
       "param_logisticregression__C                                                           1.0   \n",
       "param_logisticregression__class_weight                                               None   \n",
       "params                                  {'logisticregression__C': 1.0, 'logisticregres...   \n",
       "split0_test_score                                                                0.367347   \n",
       "split1_test_score                                                                0.291667   \n",
       "split2_test_score                                                                0.255319   \n",
       "split3_test_score                                                                0.371134   \n",
       "split4_test_score                                                                    0.24   \n",
       "mean_test_score                                                                  0.305093   \n",
       "std_test_score                                                                   0.055012   \n",
       "split0_train_score                                                               0.335958   \n",
       "split1_train_score                                                                0.37018   \n",
       "split2_train_score                                                               0.372449   \n",
       "split3_train_score                                                               0.362245   \n",
       "split4_train_score                                                               0.378517   \n",
       "mean_train_score                                                                  0.36387   \n",
       "std_train_score                                                                  0.014897   \n",
       "\n",
       "rank_test_score                                                                        21  \\\n",
       "mean_fit_time                                                                    0.105073   \n",
       "std_fit_time                                                                     0.017594   \n",
       "mean_score_time                                                                  0.025194   \n",
       "std_score_time                                                                   0.006774   \n",
       "param_logisticregression__C                                                      0.316228   \n",
       "param_logisticregression__class_weight                                               None   \n",
       "params                                  {'logisticregression__C': 0.31622776601683794,...   \n",
       "split0_test_score                                                                0.357895   \n",
       "split1_test_score                                                                0.270833   \n",
       "split2_test_score                                                                0.234043   \n",
       "split3_test_score                                                                0.336842   \n",
       "split4_test_score                                                                0.236559   \n",
       "mean_test_score                                                                  0.287234   \n",
       "std_test_score                                                                   0.051225   \n",
       "split0_train_score                                                               0.318059   \n",
       "split1_train_score                                                               0.360313   \n",
       "split2_train_score                                                               0.344828   \n",
       "split3_train_score                                                               0.349869   \n",
       "split4_train_score                                                               0.341207   \n",
       "mean_train_score                                                                 0.342855   \n",
       "std_train_score                                                                  0.013967   \n",
       "\n",
       "rank_test_score                                                                        22  \\\n",
       "mean_fit_time                                                                    0.078422   \n",
       "std_fit_time                                                                     0.013864   \n",
       "mean_score_time                                                                  0.024228   \n",
       "std_score_time                                                                   0.009151   \n",
       "param_logisticregression__C                                                           0.1   \n",
       "param_logisticregression__class_weight                                               None   \n",
       "params                                  {'logisticregression__C': 0.1, 'logisticregres...   \n",
       "split0_test_score                                                                0.361702   \n",
       "split1_test_score                                                                0.202247   \n",
       "split2_test_score                                                                 0.26087   \n",
       "split3_test_score                                                                0.319149   \n",
       "split4_test_score                                                                0.227273   \n",
       "mean_test_score                                                                  0.274248   \n",
       "std_test_score                                                                    0.05871   \n",
       "split0_train_score                                                               0.265537   \n",
       "split1_train_score                                                               0.321716   \n",
       "split2_train_score                                                               0.313187   \n",
       "split3_train_score                                                               0.319783   \n",
       "split4_train_score                                                               0.312668   \n",
       "mean_train_score                                                                 0.306578   \n",
       "std_train_score                                                                  0.020826   \n",
       "\n",
       "rank_test_score                                                                        23  \\\n",
       "mean_fit_time                                                                    0.077824   \n",
       "std_fit_time                                                                     0.013572   \n",
       "mean_score_time                                                                  0.018232   \n",
       "std_score_time                                                                   0.006275   \n",
       "param_logisticregression__C                                                      0.031623   \n",
       "param_logisticregression__class_weight                                               None   \n",
       "params                                  {'logisticregression__C': 0.03162277660168379,...   \n",
       "split0_test_score                                                                0.219512   \n",
       "split1_test_score                                                                0.141176   \n",
       "split2_test_score                                                                0.211765   \n",
       "split3_test_score                                                                0.305882   \n",
       "split4_test_score                                                                0.128205   \n",
       "mean_test_score                                                                  0.201308   \n",
       "std_test_score                                                                   0.063775   \n",
       "split0_train_score                                                               0.167702   \n",
       "split1_train_score                                                               0.240469   \n",
       "split2_train_score                                                                0.23494   \n",
       "split3_train_score                                                               0.193353   \n",
       "split4_train_score                                                               0.203593   \n",
       "mean_train_score                                                                 0.208011   \n",
       "std_train_score                                                                  0.026974   \n",
       "\n",
       "rank_test_score                                                                        24  \n",
       "mean_fit_time                                                                    0.084069  \n",
       "std_fit_time                                                                     0.028367  \n",
       "mean_score_time                                                                  0.046372  \n",
       "std_score_time                                                                   0.057999  \n",
       "param_logisticregression__C                                                          0.01  \n",
       "param_logisticregression__class_weight                                               None  \n",
       "params                                  {'logisticregression__C': 0.01, 'logisticregre...  \n",
       "split0_test_score                                                                0.054795  \n",
       "split1_test_score                                                                0.027397  \n",
       "split2_test_score                                                                0.106667  \n",
       "split3_test_score                                                                0.109589  \n",
       "split4_test_score                                                                0.028169  \n",
       "mean_test_score                                                                  0.065323  \n",
       "std_test_score                                                                   0.036327  \n",
       "split0_train_score                                                               0.061856  \n",
       "split1_train_score                                                               0.081633  \n",
       "split2_train_score                                                               0.075342  \n",
       "split3_train_score                                                                0.07483  \n",
       "split4_train_score                                                               0.087248  \n",
       "mean_train_score                                                                 0.076182  \n",
       "std_train_score                                                                  0.008485  \n",
       "\n",
       "[21 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_).set_index(\"rank_test_score\").sort_index()\n",
    "results.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The two optimal hyper parameters found were C = 0.31622776601683794 and class_weight = {0: 1, 1: 3}. The best validation f1 score was 0.504573 on the test set and 0.546282 on the training set. \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Test results\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks**\n",
    "1. Evaluate the best model on the test set. In particular show each of the following on the test set:  \n",
    "    - Plot Confusion matrix\n",
    "    - Plot Precision-recall curve \n",
    "    - Calculate average precision score\n",
    "    - Plot ROC curve\n",
    "    - Report AUC score\n",
    "3. Comment on the AUC score and give an intuitive explanation of what this value of AUC means for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from lecture 9\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression(C = 0.31622776601683794, class_weight = {0: 1, 1: 3}, max_iter = 1000))\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x14ef2eb60>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    display_labels=[\"No churn\", \"churn\"],\n",
    "    values_format = \"d\",\n",
    "    cmap = plt.cm.Blues,\n",
    "    colorbar = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_test, grid_search.predict_proba(X_test)[:, 1]\n",
    ")\n",
    "plt.plot(precision, recall, label=\"logistic regression: PR curve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.plot(\n",
    "    precision_score(y_test, grid_search.predict(X_test)),\n",
    "    recall_score(y_test, grid_search.predict(X_test)),\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "ap_lr = average_precision_score(y_test, grid_search.predict_proba(X_test)[:, 1])\n",
    "print(\"Average precision of logistic regression: {:.3f}\".format(ap_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, grid_search.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "\n",
    "default_threshold = np.argmin(np.abs(thresholds - 0.5))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[default_threshold],\n",
    "    tpr[default_threshold],\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_lr = roc_auc_score(y_test, grid_search.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC for logistic regression: {:.3f}\".format(roc_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An AUC score of 0.826 means that the model ranks 82.6% of positive examples higher than 82.6% of negative examples across the thresholds on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Regression metrics <a name=\"3\"></a>\n",
    "<hr> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) from `sklearn datasets`. The code below loads the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing_df = fetch_california_housing(as_frame=True).frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Data spitting and exploration \n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train (75%) and test (25%) splits. \n",
    "2. Explore the train split. Do you need to apply any transformations on the data? If yes, create a preprocessor with the appropriate transformations. \n",
    "3. Separate `X` and `y` to train and test splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(housing_df, test_size = 0.25, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns = ['MedHouseVal'])\n",
    "y_train = train_df[\"MedHouseVal\"]\n",
    "\n",
    "X_test = test_df.drop(columns = ['MedHouseVal'])\n",
    "y_test = test_df[\"MedHouseVal\"]                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = [\"MedInc\", \"HouseAge\", \"AveRooms\", \"AveBedrms\", \"Population\", \"AveOccup\", \"Latitude\", \"Longitude\"]  \n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_feats)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all categories are numeric, and none have any missing values. The only transformations that need to occur are to use standard scaling.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Baseline: Linear Regression \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out cross-validation using `sklearn.linear_model.LinearRegression` with default scoring. \n",
    "2. What metric is used for scoring by default? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lreg = make_pipeline(preprocessor, Ridge())\n",
    "\n",
    "scores = cross_validate(\n",
    "    pipe_lreg, X_train, y_train, return_train_score = True\n",
    ")\n",
    "\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Random Forest Regressor\n",
    "rubric={points:7}\n",
    "\n",
    "In this exercise, we are going to use [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) model which we haven't looked into yet. At this point you should feel comfortable using models with our usual ML workflow even if you don't know the details. We'll talk about `RandomForestRegressor` later in the course.  \n",
    "\n",
    "The code below defines a custom scorer called `mape_scorer` and creates dictionaries for two model (`models`) and five evaluation metrics (`score_types_reg`). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Using the `models` and the evaluation metrics `score_types_reg` in the code below, carry out cross-validation with each model, by passing the evaluation metrics to `scoring` argument of `cross_validate`. Use a pipeline with the model as an estimator if you are applying any transformations. \n",
    "2. Show results as a dataframe. \n",
    "3. Interpret the results. How do the models compare to the baseline? Which model seems to be performing well with different metrics? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "score_types_reg = {\n",
    "    \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "    \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"neg_mean_absolute_percentage_error\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    pipe = make_pipeline(StandardScaler(), models[model])\n",
    "    print(f\"Scores for {model} model.\")\n",
    "    display(pd.DataFrame(\n",
    "        cross_validate(\n",
    "            pipe,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            return_train_score = True,\n",
    "            scoring = score_types_reg\n",
    "        )\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  The Ridge model performs similar to baseline while the Random Forest model performs better as seen with the lower mean squared error scores compared to both the baseline and ridge model.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Hyperparameter optimization \n",
    "rubric={points:1}\n",
    "\n",
    "1. Carry out hyperparameter optimization using `RandomizedSearchCV` and `Ridge` with the following `param_dist`. The `alpha` hyperparameter of `Ridge` controls the fundamental tradeoff. Choose `neg_mean_absolute_percentage_error` as the HParam optimization metric.\n",
    "\n",
    "2. What was the best `alpha` hyper-parameter found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "param_dist = {\"ridge__alpha\": loguniform(1e-3, 1e3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ridge = make_pipeline(preprocessor, Ridge())\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe_ridge, param_dist, cv = 5, n_jobs=-1, return_train_score = True, scoring = \"neg_mean_absolute_percentage_error\"\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Best alpha is is ~41\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Test results\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Test the best model (from 3.4) on the test set based on the `neg_mean_absolute_percentage_error` score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = random_search.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Model interpretation  \n",
    "rubric={points:4}\n",
    "\n",
    "Ridge is a linear model and it learns coefficients associated with each feature during `fit()`. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Explore coefficients learned by the `Ridge` model above as a pandas dataframe with two columns: \n",
    "   - features \n",
    "   - coefficients\n",
    "2. Increasing which feature values would result in higher housing price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_tuned = make_pipeline(preprocessor, Ridge(alpha=49.33124076676083))\n",
    "ridge_tuned.fit(X_train, y_train)\n",
    "ridge_preds = ridge_tuned.predict(X_test)\n",
    "ridge_preds[:10]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"features\": X_train.columns,\n",
    "        \"coefficients\": ridge_tuned.named_steps[\"ridge\"].coef_,\n",
    "    }\n",
    ")\n",
    "\n",
    "df.sort_values(\"coefficients\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Increasing these features would result in higher housing prices. MedInc, AveBedrms, HouseAge \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from â€œ1â€ will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "name": "_merged",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "438px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
