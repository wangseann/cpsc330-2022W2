{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 6: Putting it all together \n",
    "### Associated lectures: All material till lecture 13 \n",
    "\n",
    "**Due date: Wednesday, March 15, 2023 at 11:59pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "- [Submission instructions](#si)\n",
    "- [Understanding the problem](#1)\n",
    "- [Data splitting](#2)\n",
    "- [EDA](#3)\n",
    "- (Optional) [Feature engineering](#4)\n",
    "- [Preprocessing and transformations](#5)\n",
    "- [Baseline model](#6)\n",
    "- [Linear models](#7)\n",
    "- [Different classifiers](#8)\n",
    "- (Optional) [Feature selection](#9)\n",
    "- [Hyperparameter optimization](#10)\n",
    "- [Interpretation and feature importances](#11)\n",
    "- [Results on the test set](#12)\n",
    "- (Optional) [Explaining predictions](#13)\n",
    "- [Summary of the results](#14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "import eli5\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2022W2/blob/main/docs/homework_instructions.md). \n",
    "\n",
    "**You may work on this homework in a group and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 3. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "<hr>\n",
    "\n",
    "At this point we are at the end of supervised machine learning part of the course. So in this homework, you will be working on an open-ended mini-project, where you will put all the different things you have learned so far together to solve an interesting problem.\n",
    "\n",
    "A few notes and tips when you work on this mini-project: \n",
    "\n",
    "#### Tips\n",
    "\n",
    "1. This mini-project is open-ended, and while working on it, there might be some situations where you'll have to use your own judgment and make your own decisions (as you would be doing when you work as a data scientist). Make sure you explain your decisions whenever necessary. \n",
    "2. **Do not include everything you ever tried in your submission** -- it's fine just to have your final code. That said, your code should be reproducible and well-documented. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code. \n",
    "3. If you realize that you are repeating a lot of code try to organize it in functions. Clear presentation of your code, experiments, and results is the key to be successful in this lab. You may use code from lecture notes or previous lab solutions with appropriate attributions. \n",
    "4. If you are having trouble running models on your laptop because of the size of the dataset, you can create your train/test split in such a way that you have less data in the train split. If you end up doing this, please write a note to the grader in the submission explaining why you are doing it.  \n",
    "\n",
    "#### Assessment\n",
    "\n",
    "We plan to grade fairly and leniently. We don't have some secret target score that you need to achieve to get a good grade. **You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results.** For example, if you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n",
    "\n",
    "#### A final note\n",
    "\n",
    "Finally, this style of this \"project\" question is different from other assignments. It'll be up to you to decide when you're \"done\" -- in fact, this is one of the hardest parts of real projects. But please don't spend WAY too much time on this... perhaps \"a few hours\" (2-8 hours???) is a good guideline for a typical submission. Of course if you're having fun you're welcome to spend as much time as you want! But, if so, try not to do it out of perfectionism or getting the best possible grade. Do it because you're learning and enjoying it. Students from the past cohorts have found such kind of labs useful and fun and I hope you enjoy it as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding the problem <a name=\"1\"></a>\n",
    "<hr>\n",
    "rubric={points:4}\n",
    "\n",
    "In this mini project, you will be working on a classification problem of predicting whether a customer will cancel the reservation they have made at a hotel. \n",
    "For this problem, you will use [Reservation Cancellation Prediction Dataset](https://www.kaggle.com/datasets/gauravduttakiit/reservation-cancellation-prediction?select=train__dataset.csv). In this data set, there are about 18.000 examples and 18 features (including the target), and the goal is to estimate whether a person will cancel their booking; this column is labeled \"booking_status\" in the data (1 = canceled). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Spend some time understanding the problem and what each feature means. You can find this information in the documentation on [the dataset page on Kaggle](https://www.kaggle.com/datasets/gauravduttakiit/reservation-cancellation-prediction?select=train__dataset.csv). Write a few sentences on your initial thoughts on the problem and the dataset. \n",
    "2. Download the dataset and read it as a pandas dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The goal of this experiment is to create a model to help hotels predict whether a not a reservation will be honored based on information about the customer. There are 18 total features in the dataset. All features are numerical. 10 of these features are not continuous values and instead have values that represent discrete classes in each feature. Three of these discrete features are binary representations and the remaining seven are ordinally encoded. The target column is a binary representation, therefore this prediction is a classification problem and not a regression problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train__dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data splitting <a name=\"2\"></a>\n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train and test portions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA <a name=\"3\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Perform exploratory data analysis on the train set.\n",
    "2. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Summarize your initial observations about the data. \n",
    "4. Pick appropriate metric/metrics for assessment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "      <th>booking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13544</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14555</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11224</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10890</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "800               2               0                     1                  3   \n",
       "13544             1               0                     0                  1   \n",
       "14555             1               0                     1                  1   \n",
       "11224             2               0                     0                  2   \n",
       "10890             2               1                     2                  4   \n",
       "\n",
       "       type_of_meal_plan  required_car_parking_space  room_type_reserved  \\\n",
       "800                    0                           0                   0   \n",
       "13544                  0                           0                   0   \n",
       "14555                  0                           0                   0   \n",
       "11224                  0                           0                   1   \n",
       "10890                  0                           0                   0   \n",
       "\n",
       "       lead_time  arrival_year  arrival_month  arrival_date  \\\n",
       "800           23          2018              1             7   \n",
       "13544         15          2018              2            19   \n",
       "14555          3          2017             11            23   \n",
       "11224        148          2018              7             8   \n",
       "10890         61          2018              7            23   \n",
       "\n",
       "       market_segment_type  repeated_guest  no_of_previous_cancellations  \\\n",
       "800                      1               0                             0   \n",
       "13544                    2               0                             0   \n",
       "14555                    2               1                             0   \n",
       "11224                    1               0                             0   \n",
       "10890                    1               0                             0   \n",
       "\n",
       "       no_of_previous_bookings_not_canceled  avg_price_per_room  \\\n",
       "800                                       0                87.0   \n",
       "13544                                     0                81.0   \n",
       "14555                                     1                65.0   \n",
       "11224                                     0               136.8   \n",
       "10890                                     0               121.5   \n",
       "\n",
       "       no_of_special_requests  booking_status  \n",
       "800                         2               0  \n",
       "13544                       0               0  \n",
       "14555                       0               0  \n",
       "11224                       1               1  \n",
       "10890                       0               1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use df.head() to assess scales of features\n",
    "train_df.head()\n",
    "# Scales of features are different. arrival_year requires ordinal encoding or OHE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14509 entries, 800 to 15725\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   no_of_adults                          14509 non-null  int64  \n",
      " 1   no_of_children                        14509 non-null  int64  \n",
      " 2   no_of_weekend_nights                  14509 non-null  int64  \n",
      " 3   no_of_week_nights                     14509 non-null  int64  \n",
      " 4   type_of_meal_plan                     14509 non-null  int64  \n",
      " 5   required_car_parking_space            14509 non-null  int64  \n",
      " 6   room_type_reserved                    14509 non-null  int64  \n",
      " 7   lead_time                             14509 non-null  int64  \n",
      " 8   arrival_year                          14509 non-null  int64  \n",
      " 9   arrival_month                         14509 non-null  int64  \n",
      " 10  arrival_date                          14509 non-null  int64  \n",
      " 11  market_segment_type                   14509 non-null  int64  \n",
      " 12  repeated_guest                        14509 non-null  int64  \n",
      " 13  no_of_previous_cancellations          14509 non-null  int64  \n",
      " 14  no_of_previous_bookings_not_canceled  14509 non-null  int64  \n",
      " 15  avg_price_per_room                    14509 non-null  float64\n",
      " 16  no_of_special_requests                14509 non-null  int64  \n",
      " 17  booking_status                        14509 non-null  int64  \n",
      "dtypes: float64(1), int64(17)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "#use df.info() to assess feature value types and missing values\n",
    "train_df.info()\n",
    "# No missing values found. avg_price_per_room has float dtype instead of integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "      <th>booking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "      <td>14509.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.849059</td>\n",
       "      <td>0.107106</td>\n",
       "      <td>0.809566</td>\n",
       "      <td>2.196223</td>\n",
       "      <td>0.319526</td>\n",
       "      <td>0.032532</td>\n",
       "      <td>0.337859</td>\n",
       "      <td>85.211524</td>\n",
       "      <td>2017.821628</td>\n",
       "      <td>7.422979</td>\n",
       "      <td>15.711765</td>\n",
       "      <td>0.803708</td>\n",
       "      <td>0.025364</td>\n",
       "      <td>0.022331</td>\n",
       "      <td>0.153629</td>\n",
       "      <td>103.558628</td>\n",
       "      <td>0.621476</td>\n",
       "      <td>0.325867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.514970</td>\n",
       "      <td>0.398989</td>\n",
       "      <td>0.869672</td>\n",
       "      <td>1.414027</td>\n",
       "      <td>0.630462</td>\n",
       "      <td>0.177413</td>\n",
       "      <td>0.775620</td>\n",
       "      <td>86.901659</td>\n",
       "      <td>0.382839</td>\n",
       "      <td>3.079938</td>\n",
       "      <td>8.759235</td>\n",
       "      <td>0.644105</td>\n",
       "      <td>0.157232</td>\n",
       "      <td>0.359667</td>\n",
       "      <td>1.720322</td>\n",
       "      <td>35.546998</td>\n",
       "      <td>0.789420</td>\n",
       "      <td>0.468714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>443.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "count  14509.000000    14509.000000          14509.000000       14509.000000   \n",
       "mean       1.849059        0.107106              0.809566           2.196223   \n",
       "std        0.514970        0.398989              0.869672           1.414027   \n",
       "min        0.000000        0.000000              0.000000           0.000000   \n",
       "25%        2.000000        0.000000              0.000000           1.000000   \n",
       "50%        2.000000        0.000000              1.000000           2.000000   \n",
       "75%        2.000000        0.000000              2.000000           3.000000   \n",
       "max        4.000000        3.000000              7.000000          17.000000   \n",
       "\n",
       "       type_of_meal_plan  required_car_parking_space  room_type_reserved  \\\n",
       "count       14509.000000                14509.000000        14509.000000   \n",
       "mean            0.319526                    0.032532            0.337859   \n",
       "std             0.630462                    0.177413            0.775620   \n",
       "min             0.000000                    0.000000            0.000000   \n",
       "25%             0.000000                    0.000000            0.000000   \n",
       "50%             0.000000                    0.000000            0.000000   \n",
       "75%             0.000000                    0.000000            0.000000   \n",
       "max             3.000000                    1.000000            6.000000   \n",
       "\n",
       "          lead_time  arrival_year  arrival_month  arrival_date  \\\n",
       "count  14509.000000  14509.000000   14509.000000  14509.000000   \n",
       "mean      85.211524   2017.821628       7.422979     15.711765   \n",
       "std       86.901659      0.382839       3.079938      8.759235   \n",
       "min        0.000000   2017.000000       1.000000      1.000000   \n",
       "25%       16.000000   2018.000000       5.000000      8.000000   \n",
       "50%       57.000000   2018.000000       8.000000     16.000000   \n",
       "75%      126.000000   2018.000000      10.000000     23.000000   \n",
       "max      443.000000   2018.000000      12.000000     31.000000   \n",
       "\n",
       "       market_segment_type  repeated_guest  no_of_previous_cancellations  \\\n",
       "count         14509.000000    14509.000000                  14509.000000   \n",
       "mean              0.803708        0.025364                      0.022331   \n",
       "std               0.644105        0.157232                      0.359667   \n",
       "min               0.000000        0.000000                      0.000000   \n",
       "25%               0.000000        0.000000                      0.000000   \n",
       "50%               1.000000        0.000000                      0.000000   \n",
       "75%               1.000000        0.000000                      0.000000   \n",
       "max               4.000000        1.000000                     13.000000   \n",
       "\n",
       "       no_of_previous_bookings_not_canceled  avg_price_per_room  \\\n",
       "count                          14509.000000        14509.000000   \n",
       "mean                               0.153629          103.558628   \n",
       "std                                1.720322           35.546998   \n",
       "min                                0.000000            0.000000   \n",
       "25%                                0.000000           80.300000   \n",
       "50%                                0.000000           99.450000   \n",
       "75%                                0.000000          120.600000   \n",
       "max                               58.000000          540.000000   \n",
       "\n",
       "       no_of_special_requests  booking_status  \n",
       "count            14509.000000    14509.000000  \n",
       "mean                 0.621476        0.325867  \n",
       "std                  0.789420        0.468714  \n",
       "min                  0.000000        0.000000  \n",
       "25%                  0.000000        0.000000  \n",
       "50%                  0.000000        0.000000  \n",
       "75%                  1.000000        1.000000  \n",
       "max                  5.000000        1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use df.describe() to assess summary statistics on dataset.\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating X_train and y_train\n",
    "X_train = train_df.drop(columns=[\"booking_status\"])\n",
    "y_train = train_df[\"booking_status\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"booking_status\"])\n",
    "y_test = test_df[\"booking_status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data Observations\n",
    "- 18 features including target (booking_status)\n",
    "- all numerical (17 integer dtypes, 1 float dtype)\n",
    "- type_of_meal_plan, required_car_parking_space, room_type reserved, market_segment_type, repeated_guest need Ordinal Encoding/OHE ? \n",
    "\n",
    "\n",
    "4. Metrics for Evaluation\n",
    "- Recall as we want to maximize predicting which customers are cancelling their booking. Using Recall will allow use to approximate how many positive examples we are correctly/incorrectly predicting. \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 4. Feature engineering <a name=\"4\"></a>\n",
    "<hr>\n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out feature engineering. In other words, extract new features relevant for the problem and work with your new feature set in the following exercises. You may have to go back and forth between feature engineering and preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe replace no_of_previous_cancellations and no_of_previous_bookings_not_canceled with a past_cancellation_rate percentage calculated as the count of previous cancellations divided by the total number of bookings (both canceled and not canceled). \n",
    "\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing and transformations <a name=\"5\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify different feature types and the transformations you would apply on each feature type. \n",
    "2. Define a column transformer, if necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Feature types \n",
    " \n",
    " - All features are numeric\n",
    " - There are no missing or null values\n",
    " - All numeric categories will be scaled with StandardScaler()\n",
    " - Although all features are numeric, some are binary/distinct representations and require OHE. These will be labeled as \"categorical\" features\n",
    " \n",
    " - arrival_year and arrival_month will be dropped as this information is already contained in the arrival_date feature. \n",
    " \n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifying features by transformations\n",
    "numerical_feats = [\"no_of_adults\", \"no_of_children\", \"no_of_weekend_nights\", \"no_of_week_nights\", \"lead_time\", \"arrival_date\", \"no_of_previous_cancellations\", \"no_of_previous_bookings_not_canceled\", \"avg_price_per_room\", \"no_of_special_requests\"]\n",
    "\n",
    "categorical_feats = [\"type_of_meal_plan\", \"required_car_parking_space\", \"room_type_reserved\", \"market_segment_type\", \"repeated_guest\"]\n",
    "\n",
    "drop_features = [\"arrival_year\", \"arrival_month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining feature transformers\n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "#creating a column_transformer preprocessing object for the dataset\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numerical_feats),\n",
    "    (categorical_transformer, categorical_feats),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming our X data\n",
    "X_transformed = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Baseline model <a name=\"6\"></a>\n",
    "<hr>\n",
    "\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try `scikit-learn`'s baseline model and report results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[[0.6741333 0.3258667]\n",
      " [0.6741333 0.3258667]\n",
      " [0.6741333 0.3258667]\n",
      " ...\n",
      " [0.6741333 0.3258667]\n",
      " [0.6741333 0.3258667]\n",
      " [0.6741333 0.3258667]]\n",
      "0.665380374862183\n"
     ]
    }
   ],
   "source": [
    "sk_dc = DummyClassifier(strategy=\"prior\")\n",
    "\n",
    "sk_dc.fit(X_transformed, y_train)\n",
    "\n",
    "print(sk_dc.predict(X_test))\n",
    "print(sk_dc.predict_proba(X_test))\n",
    "print(sk_dc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Linear models <a name=\"7\"></a>\n",
    "<hr>\n",
    "rubric={points:12}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try logistic regression as a first real attempt. \n",
    "2. Carry out hyperparameter tuning to explore different values for the complexity hyperparameter `C`. \n",
    "3. Report validation scores along with standard deviation. \n",
    "4. Summarize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'logisticregression__C': 10.0 ** np.arange(-2, 2, 0.5), #try with -2,2,0.5\n",
    "}\n",
    "\n",
    "pipe_lr = make_pipeline(preprocessor, LogisticRegression(max_iter = 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8023984219895179\n",
      "{'logisticregression__C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    pipe_lr, param_grid, cv = 5, n_jobs = -1, return_train_score = True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.160558</td>\n",
       "      <td>0.188002</td>\n",
       "      <td>0.294496</td>\n",
       "      <td>0.447148</td>\n",
       "      <td>0.682286</td>\n",
       "      <td>1.05253</td>\n",
       "      <td>1.734358</td>\n",
       "      <td>1.225265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.011651</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.03909</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>0.187779</td>\n",
       "      <td>0.229477</td>\n",
       "      <td>0.141805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.017618</td>\n",
       "      <td>0.017972</td>\n",
       "      <td>0.016111</td>\n",
       "      <td>0.01836</td>\n",
       "      <td>0.020209</td>\n",
       "      <td>0.022769</td>\n",
       "      <td>0.017809</td>\n",
       "      <td>0.01421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.006176</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>0.007048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.031623</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.622777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'logisticregression__C': 0.01}</td>\n",
       "      <td>{'logisticregression__C': 0.03162277660168379}</td>\n",
       "      <td>{'logisticregression__C': 0.1}</td>\n",
       "      <td>{'logisticregression__C': 0.31622776601683794}</td>\n",
       "      <td>{'logisticregression__C': 1.0}</td>\n",
       "      <td>{'logisticregression__C': 3.1622776601683795}</td>\n",
       "      <td>{'logisticregression__C': 10.0}</td>\n",
       "      <td>{'logisticregression__C': 31.622776601683793}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.800138</td>\n",
       "      <td>0.80255</td>\n",
       "      <td>0.801861</td>\n",
       "      <td>0.801172</td>\n",
       "      <td>0.800138</td>\n",
       "      <td>0.801516</td>\n",
       "      <td>0.801861</td>\n",
       "      <td>0.801172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.804618</td>\n",
       "      <td>0.807374</td>\n",
       "      <td>0.811165</td>\n",
       "      <td>0.810131</td>\n",
       "      <td>0.809786</td>\n",
       "      <td>0.810476</td>\n",
       "      <td>0.810476</td>\n",
       "      <td>0.81082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.79807</td>\n",
       "      <td>0.796692</td>\n",
       "      <td>0.797381</td>\n",
       "      <td>0.796692</td>\n",
       "      <td>0.797381</td>\n",
       "      <td>0.797037</td>\n",
       "      <td>0.797037</td>\n",
       "      <td>0.797037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.793935</td>\n",
       "      <td>0.799449</td>\n",
       "      <td>0.800482</td>\n",
       "      <td>0.800482</td>\n",
       "      <td>0.800482</td>\n",
       "      <td>0.800827</td>\n",
       "      <td>0.801172</td>\n",
       "      <td>0.800827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.801448</td>\n",
       "      <td>0.79938</td>\n",
       "      <td>0.801103</td>\n",
       "      <td>0.801103</td>\n",
       "      <td>0.800414</td>\n",
       "      <td>0.799724</td>\n",
       "      <td>0.800069</td>\n",
       "      <td>0.800069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.799642</td>\n",
       "      <td>0.801089</td>\n",
       "      <td>0.802398</td>\n",
       "      <td>0.801916</td>\n",
       "      <td>0.80164</td>\n",
       "      <td>0.801916</td>\n",
       "      <td>0.802123</td>\n",
       "      <td>0.801985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.003558</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.00464</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.004544</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.004652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.801671</td>\n",
       "      <td>0.802274</td>\n",
       "      <td>0.803395</td>\n",
       "      <td>0.803739</td>\n",
       "      <td>0.80305</td>\n",
       "      <td>0.804256</td>\n",
       "      <td>0.804342</td>\n",
       "      <td>0.803653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.798914</td>\n",
       "      <td>0.80081</td>\n",
       "      <td>0.801327</td>\n",
       "      <td>0.801154</td>\n",
       "      <td>0.800982</td>\n",
       "      <td>0.801671</td>\n",
       "      <td>0.801844</td>\n",
       "      <td>0.801844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.800724</td>\n",
       "      <td>0.801758</td>\n",
       "      <td>0.803395</td>\n",
       "      <td>0.803395</td>\n",
       "      <td>0.803567</td>\n",
       "      <td>0.803567</td>\n",
       "      <td>0.803653</td>\n",
       "      <td>0.803567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>0.800896</td>\n",
       "      <td>0.802533</td>\n",
       "      <td>0.804256</td>\n",
       "      <td>0.803998</td>\n",
       "      <td>0.804515</td>\n",
       "      <td>0.804773</td>\n",
       "      <td>0.804859</td>\n",
       "      <td>0.804859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>0.800569</td>\n",
       "      <td>0.802464</td>\n",
       "      <td>0.802636</td>\n",
       "      <td>0.803842</td>\n",
       "      <td>0.80367</td>\n",
       "      <td>0.803498</td>\n",
       "      <td>0.803325</td>\n",
       "      <td>0.803411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.800555</td>\n",
       "      <td>0.801968</td>\n",
       "      <td>0.803002</td>\n",
       "      <td>0.803226</td>\n",
       "      <td>0.803157</td>\n",
       "      <td>0.803553</td>\n",
       "      <td>0.803605</td>\n",
       "      <td>0.803467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           0  \\\n",
       "mean_fit_time                                       0.160558   \n",
       "std_fit_time                                        0.011651   \n",
       "mean_score_time                                     0.017618   \n",
       "std_score_time                                      0.001629   \n",
       "param_logisticregression__C                             0.01   \n",
       "params                       {'logisticregression__C': 0.01}   \n",
       "split0_test_score                                   0.800138   \n",
       "split1_test_score                                   0.804618   \n",
       "split2_test_score                                    0.79807   \n",
       "split3_test_score                                   0.793935   \n",
       "split4_test_score                                   0.801448   \n",
       "mean_test_score                                     0.799642   \n",
       "std_test_score                                      0.003558   \n",
       "rank_test_score                                            8   \n",
       "split0_train_score                                  0.801671   \n",
       "split1_train_score                                  0.798914   \n",
       "split2_train_score                                  0.800724   \n",
       "split3_train_score                                  0.800896   \n",
       "split4_train_score                                  0.800569   \n",
       "mean_train_score                                    0.800555   \n",
       "std_train_score                                     0.000904   \n",
       "\n",
       "                                                                          1  \\\n",
       "mean_fit_time                                                      0.188002   \n",
       "std_fit_time                                                       0.007188   \n",
       "mean_score_time                                                    0.017972   \n",
       "std_score_time                                                     0.003233   \n",
       "param_logisticregression__C                                        0.031623   \n",
       "params                       {'logisticregression__C': 0.03162277660168379}   \n",
       "split0_test_score                                                   0.80255   \n",
       "split1_test_score                                                  0.807374   \n",
       "split2_test_score                                                  0.796692   \n",
       "split3_test_score                                                  0.799449   \n",
       "split4_test_score                                                   0.79938   \n",
       "mean_test_score                                                    0.801089   \n",
       "std_test_score                                                     0.003649   \n",
       "rank_test_score                                                           7   \n",
       "split0_train_score                                                 0.802274   \n",
       "split1_train_score                                                  0.80081   \n",
       "split2_train_score                                                 0.801758   \n",
       "split3_train_score                                                 0.802533   \n",
       "split4_train_score                                                 0.802464   \n",
       "mean_train_score                                                   0.801968   \n",
       "std_train_score                                                    0.000639   \n",
       "\n",
       "                                                          2  \\\n",
       "mean_fit_time                                      0.294496   \n",
       "std_fit_time                                         0.0179   \n",
       "mean_score_time                                    0.016111   \n",
       "std_score_time                                     0.005314   \n",
       "param_logisticregression__C                             0.1   \n",
       "params                       {'logisticregression__C': 0.1}   \n",
       "split0_test_score                                  0.801861   \n",
       "split1_test_score                                  0.811165   \n",
       "split2_test_score                                  0.797381   \n",
       "split3_test_score                                  0.800482   \n",
       "split4_test_score                                  0.801103   \n",
       "mean_test_score                                    0.802398   \n",
       "std_test_score                                      0.00464   \n",
       "rank_test_score                                           1   \n",
       "split0_train_score                                 0.803395   \n",
       "split1_train_score                                 0.801327   \n",
       "split2_train_score                                 0.803395   \n",
       "split3_train_score                                 0.804256   \n",
       "split4_train_score                                 0.802636   \n",
       "mean_train_score                                   0.803002   \n",
       "std_train_score                                    0.000982   \n",
       "\n",
       "                                                                          3  \\\n",
       "mean_fit_time                                                      0.447148   \n",
       "std_fit_time                                                        0.03909   \n",
       "mean_score_time                                                     0.01836   \n",
       "std_score_time                                                     0.002322   \n",
       "param_logisticregression__C                                        0.316228   \n",
       "params                       {'logisticregression__C': 0.31622776601683794}   \n",
       "split0_test_score                                                  0.801172   \n",
       "split1_test_score                                                  0.810131   \n",
       "split2_test_score                                                  0.796692   \n",
       "split3_test_score                                                  0.800482   \n",
       "split4_test_score                                                  0.801103   \n",
       "mean_test_score                                                    0.801916   \n",
       "std_test_score                                                     0.004428   \n",
       "rank_test_score                                                           4   \n",
       "split0_train_score                                                 0.803739   \n",
       "split1_train_score                                                 0.801154   \n",
       "split2_train_score                                                 0.803395   \n",
       "split3_train_score                                                 0.803998   \n",
       "split4_train_score                                                 0.803842   \n",
       "mean_train_score                                                   0.803226   \n",
       "std_train_score                                                    0.001054   \n",
       "\n",
       "                                                          4  \\\n",
       "mean_fit_time                                      0.682286   \n",
       "std_fit_time                                       0.035951   \n",
       "mean_score_time                                    0.020209   \n",
       "std_score_time                                     0.006176   \n",
       "param_logisticregression__C                             1.0   \n",
       "params                       {'logisticregression__C': 1.0}   \n",
       "split0_test_score                                  0.800138   \n",
       "split1_test_score                                  0.809786   \n",
       "split2_test_score                                  0.797381   \n",
       "split3_test_score                                  0.800482   \n",
       "split4_test_score                                  0.800414   \n",
       "mean_test_score                                     0.80164   \n",
       "std_test_score                                     0.004233   \n",
       "rank_test_score                                           6   \n",
       "split0_train_score                                  0.80305   \n",
       "split1_train_score                                 0.800982   \n",
       "split2_train_score                                 0.803567   \n",
       "split3_train_score                                 0.804515   \n",
       "split4_train_score                                  0.80367   \n",
       "mean_train_score                                   0.803157   \n",
       "std_train_score                                    0.001185   \n",
       "\n",
       "                                                                         5  \\\n",
       "mean_fit_time                                                      1.05253   \n",
       "std_fit_time                                                      0.187779   \n",
       "mean_score_time                                                   0.022769   \n",
       "std_score_time                                                    0.007731   \n",
       "param_logisticregression__C                                       3.162278   \n",
       "params                       {'logisticregression__C': 3.1622776601683795}   \n",
       "split0_test_score                                                 0.801516   \n",
       "split1_test_score                                                 0.810476   \n",
       "split2_test_score                                                 0.797037   \n",
       "split3_test_score                                                 0.800827   \n",
       "split4_test_score                                                 0.799724   \n",
       "mean_test_score                                                   0.801916   \n",
       "std_test_score                                                    0.004544   \n",
       "rank_test_score                                                          5   \n",
       "split0_train_score                                                0.804256   \n",
       "split1_train_score                                                0.801671   \n",
       "split2_train_score                                                0.803567   \n",
       "split3_train_score                                                0.804773   \n",
       "split4_train_score                                                0.803498   \n",
       "mean_train_score                                                  0.803553   \n",
       "std_train_score                                                   0.001051   \n",
       "\n",
       "                                                           6  \\\n",
       "mean_fit_time                                       1.734358   \n",
       "std_fit_time                                        0.229477   \n",
       "mean_score_time                                     0.017809   \n",
       "std_score_time                                      0.003684   \n",
       "param_logisticregression__C                             10.0   \n",
       "params                       {'logisticregression__C': 10.0}   \n",
       "split0_test_score                                   0.801861   \n",
       "split1_test_score                                   0.810476   \n",
       "split2_test_score                                   0.797037   \n",
       "split3_test_score                                   0.801172   \n",
       "split4_test_score                                   0.800069   \n",
       "mean_test_score                                     0.802123   \n",
       "std_test_score                                      0.004491   \n",
       "rank_test_score                                            2   \n",
       "split0_train_score                                  0.804342   \n",
       "split1_train_score                                  0.801844   \n",
       "split2_train_score                                  0.803653   \n",
       "split3_train_score                                  0.804859   \n",
       "split4_train_score                                  0.803325   \n",
       "mean_train_score                                    0.803605   \n",
       "std_train_score                                     0.001029   \n",
       "\n",
       "                                                                         7  \n",
       "mean_fit_time                                                     1.225265  \n",
       "std_fit_time                                                      0.141805  \n",
       "mean_score_time                                                    0.01421  \n",
       "std_score_time                                                    0.007048  \n",
       "param_logisticregression__C                                      31.622777  \n",
       "params                       {'logisticregression__C': 31.622776601683793}  \n",
       "split0_test_score                                                 0.801172  \n",
       "split1_test_score                                                  0.81082  \n",
       "split2_test_score                                                 0.797037  \n",
       "split3_test_score                                                 0.800827  \n",
       "split4_test_score                                                 0.800069  \n",
       "mean_test_score                                                   0.801985  \n",
       "std_test_score                                                    0.004652  \n",
       "rank_test_score                                                          3  \n",
       "split0_train_score                                                0.803653  \n",
       "split1_train_score                                                0.801844  \n",
       "split2_train_score                                                0.803567  \n",
       "split3_train_score                                                0.804859  \n",
       "split4_train_score                                                0.803411  \n",
       "mean_train_score                                                  0.803467  \n",
       "std_train_score                                                   0.000961  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_grid = cross_validate(\n",
    "    grid_search, X_train, y_train, return_train_score=True\n",
    ")\n",
    "\n",
    "\n",
    "pd.DataFrame(scores_grid)\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 8. Different classifiers <a name=\"8\"></a>\n",
    "<hr>\n",
    "rubric={points:15}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try at least 3 other models aside from logistic regression. At least one of these models should be a tree-based ensemble model (e.g., lgbm, random forest, xgboost). \n",
    "2. Summarize your results. Can you beat logistic regression? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fit_time  score_time  test_score  train_score\n",
      "0  0.177237    0.019094    0.873880     0.898337\n",
      "1  0.157623    0.020832    0.888008     0.894460\n",
      "2  0.156438    0.017781    0.865610     0.897562\n",
      "3  0.155025    0.017795    0.864232     0.895580\n",
      "4  0.170316    0.017595    0.873492     0.896795\n"
     ]
    }
   ],
   "source": [
    "pipe_lgbm = make_pipeline(\n",
    "    preprocessor, LGBMClassifier(random_state=123, n_jobs=-1)\n",
    ")\n",
    "\n",
    "score_lgbm = cross_validate(\n",
    "    pipe_lgbm, X_train, y_train, return_train_score=True\n",
    ")\n",
    "\n",
    "lgbm_df = pd.DataFrame(score_lgbm)\n",
    "\n",
    "print(lgbm_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fit_time  score_time  test_score  train_score\n",
      "0  0.888175    0.053411    0.876292     0.996812\n",
      "1  0.799578    0.052953    0.888353     0.996037\n",
      "2  0.775968    0.050255    0.874914     0.996381\n",
      "3  0.757759    0.052705    0.872846     0.996468\n",
      "4  0.738213    0.051479    0.875215     0.996813\n"
     ]
    }
   ],
   "source": [
    "pipe_rf = make_pipeline(\n",
    "    preprocessor, RandomForestClassifier(random_state=123, n_jobs=-1)\n",
    ")\n",
    "\n",
    "score_rf = cross_validate (\n",
    "    pipe_rf, X_train, y_train, return_train_score=True\n",
    ")\n",
    "\n",
    "rf_df = pd.DataFrame(score_rf)\n",
    "\n",
    "print(rf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fit_time  score_time  test_score  train_score\n",
      "0  1.174755    0.016551    0.870434     0.932885\n",
      "1  1.093472    0.015378    0.883529     0.926510\n",
      "2  1.159798    0.016822    0.862164     0.930042\n",
      "3  1.100173    0.018193    0.862853     0.931679\n",
      "4  1.127384    0.015990    0.870390     0.933236\n"
     ]
    }
   ],
   "source": [
    "pipe_xg = make_pipeline(\n",
    "    preprocessor, xgb.XGBClassifier(n_jobs=-1)\n",
    ")\n",
    "\n",
    "score_xg = cross_validate(\n",
    "    pipe_xg, X_train, y_train, return_train_score=True\n",
    ")\n",
    "\n",
    "xg_df = pd.DataFrame(score_xg)\n",
    "\n",
    "print(xg_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. All three models were able to reach a higher valdiation score than Logistical Regression. Rf, LGBMC, XGBC all had scores >= 0.85 while Logistical Regression scores are < 0.81. LightGBM seemed to be less overfit on the training data, as it was able to maintain a similar test score to the other models without an excessively high score in training. This could indicate it is the more trustworthy model in this case. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 9. Feature selection <a name=\"9\"></a>\n",
    "<hr>\n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to select relevant features. You may try `RFECV` or forward selection. Do the results improve with feature selection? Summarize your results. If you see improvements in the results, keep feature selection in your pipeline. If not, you may abandon it in the next exercises. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fit_time  score_time  test_score  train_score\n",
      "0  19.327819    0.024214    0.874914     0.898251\n",
      "1  22.214469    0.021617    0.885252     0.891789\n",
      "2  19.507927    0.018233    0.865610     0.898854\n",
      "3  19.914379    0.017965    0.866644     0.893340\n",
      "4  19.247902    0.017849    0.871768     0.896968\n"
     ]
    }
   ],
   "source": [
    "pipe_lgbm = make_pipeline(\n",
    "    preprocessor, RFECV(estimator=LGBMClassifier()), LGBMClassifier(random_state=123, n_jobs=-1)\n",
    ")\n",
    "\n",
    "score_lgbm = cross_validate(\n",
    "    pipe_lgbm, X_train, y_train, return_train_score=True\n",
    ")\n",
    "\n",
    "lgbm_df = pd.DataFrame(score_lgbm)\n",
    "\n",
    "print(lgbm_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fit_time  score_time  test_score  train_score\n",
      "0  139.741779    0.064121    0.878015     0.996898\n",
      "1  150.198344    0.047526    0.887664     0.996123\n",
      "2  146.693794    0.047705    0.870434     0.996209\n",
      "3  134.986772    0.051656    0.872157     0.996468\n",
      "4  143.351186    0.047997    0.875215     0.996813\n"
     ]
    }
   ],
   "source": [
    "pipe_rf = make_pipeline(\n",
    "    preprocessor, RFECV(estimator=RandomForestClassifier()), RandomForestClassifier(random_state=123, n_jobs=-1)\n",
    ")\n",
    "\n",
    "score_rf = cross_validate (\n",
    "    pipe_rf, X_train, y_train, return_train_score=True\n",
    ")\n",
    "\n",
    "rf_df = pd.DataFrame(score_rf)\n",
    "\n",
    "print(rf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fit_time  score_time  test_score  train_score\n",
      "0  105.564357    0.016455    0.872846     0.916861\n",
      "1   93.967879    0.016358    0.890765     0.926251\n",
      "2   87.493266    0.016283    0.862164     0.930042\n",
      "3   91.667238    0.017118    0.866644     0.930559\n",
      "4   91.371901    0.016172    0.870390     0.932633\n"
     ]
    }
   ],
   "source": [
    "pipe_xg = make_pipeline(\n",
    "    preprocessor, RFECV(estimator=xgb.XGBClassifier()), xgb.XGBClassifier(n_jobs=-1)\n",
    ")\n",
    "\n",
    "score_xg = cross_validate(\n",
    "    pipe_xg, X_train, y_train, return_train_score=True\n",
    ")\n",
    "\n",
    "xg_df = pd.DataFrame(score_xg)\n",
    "\n",
    "print(xg_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Hyperparameter optimization <a name=\"10\"></a>\n",
    "<hr>\n",
    "rubric={points:15}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. You may pick one of the best performing models from the previous exercise and tune hyperparameters only for that model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods. \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the LightGBM for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 17\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Define the search strategy and perform hyperparameter optimization\u001b[39;00m\n\u001b[1;32m      8\u001b[0m opt \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m      9\u001b[0m     pipe_lgbm,\n\u001b[1;32m     10\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m score_lgbm \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m   \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m lgbm_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(score_lgbm)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(lgbm_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1753\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1753\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "param_dist = {\n",
    "    'lgbmclassifier__n_estimators': randint(100, 500),\n",
    "    'lgbmclassifier__learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "\n",
    "opt = RandomizedSearchCV(\n",
    "    pipe_lgbm,\n",
    "    param_distributions=param_dist,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    n_iter=10,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "score_lgbm = cross_validate(\n",
    "   opt, X_train, y_train, return_train_score=True\n",
    ")\n",
    "\n",
    "lgbm_df = pd.DataFrame(score_lgbm)\n",
    "\n",
    "print(lgbm_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Interpretation and feature importances <a name=\"1\"></a>\n",
    "<hr>\n",
    "rubric={points:15}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Use the methods we saw in class (e.g., `eli5`, `shap`) (or any other methods of your choice) to explain feature importances of one of the best performing models. Summarize your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'columntransformer': ColumnTransformer(transformers=[('pipeline-1',\n",
      "                                 Pipeline(steps=[('standardscaler',\n",
      "                                                  StandardScaler())]),\n",
      "                                 ['no_of_adults', 'no_of_children',\n",
      "                                  'no_of_weekend_nights', 'no_of_week_nights',\n",
      "                                  'lead_time', 'arrival_date',\n",
      "                                  'no_of_previous_cancellations',\n",
      "                                  'no_of_previous_bookings_not_canceled',\n",
      "                                  'avg_price_per_room',\n",
      "                                  'no_of_special_requests']),\n",
      "                                ('pipeline-2',\n",
      "                                 Pipeline(steps=[('onehotencoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                 ['type_of_meal_plan',\n",
      "                                  'required_car_parking_space',\n",
      "                                  'room_type_reserved', 'market_segment_type',\n",
      "                                  'repeated_guest']),\n",
      "                                ('drop', 'drop',\n",
      "                                 ['arrival_year', 'arrival_month'])]), 'rfecv': RFECV(estimator=LGBMClassifier()), 'lgbmclassifier': LGBMClassifier(random_state=123)}\n"
     ]
    }
   ],
   "source": [
    "print(pipe_lgbm.named_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.4073\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lead_time\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.16%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1698\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                avg_price_per_room\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.09%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1284\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                no_of_special_requests\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1143\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                market_segment_type_1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.05%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0401\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                arrival_date\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.87%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0287\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                no_of_adults\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0284\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                no_of_week_nights\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0267\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                no_of_weekend_nights\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0149\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                required_car_parking_space_0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0119\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                market_segment_type_0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.10%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0049\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                market_segment_type_2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.15%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                room_type_reserved_1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0038\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                type_of_meal_plan_0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.33%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0032\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                repeated_guest_0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                type_of_meal_plan_1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.36%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                room_type_reserved_0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0022\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                no_of_children\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.55%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0018\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                type_of_meal_plan_2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.62%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                room_type_reserved_4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.76%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                no_of_previous_bookings_not_canceled\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.76%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 10 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator='LGBMClassifier(random_state=123)', description='\\nLightGBM feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='feature importances', is_regression=False, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='lead_time', weight=0.40731723226344996, std=None, value=None), FeatureWeight(feature='avg_price_per_room', weight=0.1698428482019566, std=None, value=None), FeatureWeight(feature='no_of_special_requests', weight=0.12837389727567441, std=None, value=None), FeatureWeight(feature='market_segment_type_1', weight=0.1142728018219353, std=None, value=None), FeatureWeight(feature='arrival_date', weight=0.040147707075952194, std=None, value=None), FeatureWeight(feature='no_of_adults', weight=0.028738215418689254, std=None, value=None), FeatureWeight(feature='no_of_week_nights', weight=0.028381494743962822, std=None, value=None), FeatureWeight(feature='no_of_weekend_nights', weight=0.026749417023994634, std=None, value=None), FeatureWeight(feature='required_car_parking_space_0', weight=0.014902490658360038, std=None, value=None), FeatureWeight(feature='market_segment_type_0', weight=0.01185213219332088, std=None, value=None), FeatureWeight(feature='market_segment_type_2', weight=0.004851755834481667, std=None, value=None), FeatureWeight(feature='room_type_reserved_1', weight=0.004485654636856337, std=None, value=None), FeatureWeight(feature='type_of_meal_plan_0', weight=0.003761644163105096, std=None, value=None), FeatureWeight(feature='repeated_guest_0', weight=0.003210201063483706, std=None, value=None), FeatureWeight(feature='type_of_meal_plan_1', weight=0.003028387674416816, std=None, value=None), FeatureWeight(feature='room_type_reserved_0', weight=0.0030061720240545232, std=None, value=None), FeatureWeight(feature='no_of_children', weight=0.002212017326435036, std=None, value=None), FeatureWeight(feature='type_of_meal_plan_2', weight=0.0018021420612702459, std=None, value=None), FeatureWeight(feature='room_type_reserved_4', weight=0.0014009882051208109, std=None, value=None), FeatureWeight(feature='no_of_previous_bookings_not_canceled', weight=0.0007379709186539423, std=None, value=None)], remaining=10), decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lgbm = make_pipeline(\n",
    "    preprocessor, LGBMClassifier(random_state=123, n_jobs=-1)\n",
    ")\n",
    "\n",
    "ohe_feature_names = (\n",
    "    pipe_lgbm.named_steps[\"columntransformer\"].named_transformers_[\"pipeline-2\"].named_steps[\"onehotencoder\"].get_feature_names_out().tolist()\n",
    ")\n",
    "\n",
    "feature_names = numerical_feats + ohe_feature_names\n",
    "\n",
    "\n",
    "pipe_lgbm.fit(X_train, y_train)\n",
    "eli5.explain_weights(pipe_lgbm.named_steps[\"lgbmclassifier\"], feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the eli5 summary chart, we can see that the features of lead_time, avg_price_per_room, no_of_special_requests, and market_segment_type_1 are the features with the heightest weight in feature importance for the LGBMClassifier model.  <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Results on the test set <a name=\"12\"></a>\n",
    "<hr>\n",
    "\n",
    "rubric={points:5}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try your best performing model on the test data and report test scores. \n",
    "2. Do the test scores agree with the validation scores from before? To what extent do you trust your results? Do you think you've had issues with optimization bias? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8705\n",
      "Precision: 0.8419\n",
      "Recall: 0.7545\n",
      "F1 score: 0.7958\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe_lgbm.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Report the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The test scores are similar to the mean cross validation scores generated from before. The individual scores indicate that the model is performing decently well while there is still some room for improvement, particularly for recall. For instance, a score of 0.7545 suggests that there are some positive instances that the model missed, and thus there are some false negatives. Furthermore, since the performance on the training data and test data are similar, there seems to be little overfitting to the training data for the model. Therefore, we would not expect issues concerning optimization bias. \n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 13. Explaining predictions \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks**\n",
    "\n",
    "1. Take one or two test predictions and explain them with SHAP force plots.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary of results <a name=\"13\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Report your final test score along with the metric you used. \n",
    "2. Write concluding remarks.\n",
    "3. Discuss other ideas that you did not try but could potentially improve the performance/interpretability . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The final test score is approxmiately 0.8705 on the test split, with a recall score of 0.7545.\n",
    "2. These two scores suggest that our LightGBM Classifier model is performing well in this classification problem, correctly predicting 87.05% of cases in the test split. We observed that ensemble models generally performed more accurately than simple Logistical Regression (with scores around 80%) and the DummyClassifier (with scores around 66%). Hyperparameter optimization with GridSearchCV did not significantly increase the test scores, however, it did raise the LGBM model's training scores from ~85% to over 95% in some cases. Perhaps this signifies some overfitting. Furthermore, feature importance analysis showed that lead_time, avg_price_per_room, no_of_special_requests, and the OHE feature market_segment_type_1 were the most predictive features of whether or not someone would cancel their booking. \n",
    "3. Hyperparameter optimization using Bayesian optimization would potentially result in improved performance due to its guided search of the parameter space, while the current method using grid search is limited to a slow, systematic search limited by the parameter grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from 1 will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
